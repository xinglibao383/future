[2025-10-17 00:37:39] 备注: 使用场景1、场景2、场景3数据, 对transformer调参
[2025-10-17 00:37:39] mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet50, imu_generator=transformer, lstm_hidden=128, lstm_layers=2, lstm_dropout=0.1, gru_hidden=128, gru_layers=2, gru_dropout=0.1, transformer_hidden=512, transformer_layers=6, transformer_nhead=8, transformer_dropout=0.3, use_len=45, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-17 00:41:29] Epoch: 0, train loss1: 0.2800, train loss2: 0.7691, train loss3: 0.2902, train mpjpe1: 132.9304, train mpjpe2: 138.6871
[2025-10-17 00:41:29] Epoch: 0,   val loss1: 0.3793,   val loss2: 0.6526,   val loss3: 0.3845,   val mpjpe1: 177.7372,   val mpjpe2: 176.3028
[2025-10-17 00:46:52] Epoch: 1, train loss1: 0.2273, train loss2: 0.6476, train loss3: 0.2353, train mpjpe1: 113.8508, train mpjpe2: 119.0617
[2025-10-17 00:46:52] Epoch: 1,   val loss1: 0.2128,   val loss2: 0.6388,   val loss3: 0.2179,   val mpjpe1: 120.2155,   val mpjpe2: 120.8107
[2025-10-17 00:54:37] Epoch: 2, train loss1: 0.2106, train loss2: 0.6381, train loss3: 0.2189, train mpjpe1: 105.9222, train mpjpe2: 111.6322
[2025-10-17 00:54:37] Epoch: 2,   val loss1: 0.2116,   val loss2: 0.6337,   val loss3: 0.2173,   val mpjpe1: 118.8211,   val mpjpe2: 119.2719
[2025-10-17 01:03:34] Epoch: 3, train loss1: 0.2019, train loss2: 0.6353, train loss3: 0.2104, train mpjpe1: 102.1242, train mpjpe2: 108.3976
[2025-10-17 01:03:34] Epoch: 3,   val loss1: 0.2138,   val loss2: nan,   val loss3: nan,   val mpjpe1: 132.9263,   val mpjpe2: nan
[2025-10-17 01:12:28] Epoch: 4, train loss1: 0.1965, train loss2: 0.6336, train loss3: 0.2062, train mpjpe1: 101.4377, train mpjpe2: 107.0569
[2025-10-17 01:12:28] Epoch: 4,   val loss1: 0.5859,   val loss2: nan,   val loss3: nan,   val mpjpe1: 434.2546,   val mpjpe2: nan
[2025-10-17 01:21:33] Epoch: 5, train loss1: 0.2068, train loss2: 0.6432, train loss3: 0.2161, train mpjpe1: 107.1191, train mpjpe2: 113.1617
[2025-10-17 01:21:33] Epoch: 5,   val loss1: 0.2040,   val loss2: 0.6336,   val loss3: 0.2107,   val mpjpe1: 123.0355,   val mpjpe2: 121.8244
[2025-10-17 01:30:45] Epoch: 6, train loss1: 0.1914, train loss2: 0.6331, train loss3: 0.2013, train mpjpe1: 100.8323, train mpjpe2: 106.9135
[2025-10-17 01:30:45] Epoch: 6,   val loss1: 0.1966,   val loss2: 0.6301,   val loss3: 0.1990,   val mpjpe1: 124.4592,   val mpjpe2: 118.9027
[2025-10-17 01:40:34] Epoch: 7, train loss1: 0.1980, train loss2: 0.6329, train loss3: 0.2077, train mpjpe1: 102.3182, train mpjpe2: 108.6451
[2025-10-17 01:40:34] Epoch: 7,   val loss1: 0.2234,   val loss2: 0.6312,   val loss3: 0.2190,   val mpjpe1: 134.5378,   val mpjpe2: 125.1504
[2025-10-17 01:50:27] Epoch: 8, train loss1: 0.1914, train loss2: 0.6327, train loss3: 0.2015, train mpjpe1: 99.5250, train mpjpe2: 105.4723
[2025-10-17 01:50:27] Epoch: 8,   val loss1: 0.2796,   val loss2: 0.6379,   val loss3: 0.2757,   val mpjpe1: 161.8268,   val mpjpe2: 151.3017
[2025-10-17 02:00:21] Epoch: 9, train loss1: 0.1919, train loss2: 0.6321, train loss3: 0.2024, train mpjpe1: 97.6793, train mpjpe2: 103.8796
[2025-10-17 02:00:21] Epoch: 9,   val loss1: 0.1902,   val loss2: 0.6294,   val loss3: 0.2047,   val mpjpe1: 106.5883,   val mpjpe2: 109.3768
[2025-10-17 02:10:09] Epoch: 10, train loss1: 0.1813, train loss2: 0.6307, train loss3: 0.1916, train mpjpe1: 95.7989, train mpjpe2: 101.6350
[2025-10-17 02:10:09] Epoch: 10,   val loss1: 0.2074,   val loss2: nan,   val loss3: nan,   val mpjpe1: 122.1988,   val mpjpe2: nan
[2025-10-17 02:19:57] Epoch: 11, train loss1: 0.1831, train loss2: 0.6307, train loss3: 0.1939, train mpjpe1: 97.1844, train mpjpe2: 103.1330
[2025-10-17 02:19:57] Epoch: 11,   val loss1: 0.2799,   val loss2: 0.6294,   val loss3: 0.2827,   val mpjpe1: 139.2232,   val mpjpe2: 145.2512
[2025-10-17 02:29:43] Epoch: 12, train loss1: 0.1845, train loss2: 0.6305, train loss3: 0.1947, train mpjpe1: 99.4867, train mpjpe2: 104.8512
[2025-10-17 02:29:43] Epoch: 12,   val loss1: 0.1752,   val loss2: 0.6285,   val loss3: 0.1835,   val mpjpe1: 101.7521,   val mpjpe2: 102.4940
[2025-10-17 02:39:29] Epoch: 13, train loss1: 0.1816, train loss2: 0.6300, train loss3: 0.1927, train mpjpe1: 97.0182, train mpjpe2: 102.3354
[2025-10-17 02:39:29] Epoch: 13,   val loss1: 0.1945,   val loss2: 0.6291,   val loss3: 0.2009,   val mpjpe1: 113.1598,   val mpjpe2: 112.7856
[2025-10-17 02:49:12] Epoch: 14, train loss1: 0.1955, train loss2: 0.6339, train loss3: 0.2093, train mpjpe1: 98.6308, train mpjpe2: 104.8684
[2025-10-17 02:49:12] Epoch: 14,   val loss1: 0.1892,   val loss2: 0.6297,   val loss3: 0.1978,   val mpjpe1: 100.5053,   val mpjpe2: 103.6896
[2025-10-17 02:58:46] Epoch: 15, train loss1: 0.1881, train loss2: 0.6307, train loss3: 0.2004, train mpjpe1: 99.7974, train mpjpe2: 105.5398
[2025-10-17 02:58:46] Epoch: 15,   val loss1: 0.3276,   val loss2: nan,   val loss3: nan,   val mpjpe1: 143.9976,   val mpjpe2: nan
[2025-10-17 03:08:27] Epoch: 16, train loss1: 0.1887, train loss2: 0.6297, train loss3: 0.1983, train mpjpe1: 99.1533, train mpjpe2: 105.0561
[2025-10-17 03:08:27] Epoch: 16,   val loss1: 0.1796,   val loss2: 0.6286,   val loss3: 0.1880,   val mpjpe1: 97.2384,   val mpjpe2: 99.9197
[2025-10-17 03:18:02] Epoch: 17, train loss1: 0.1845, train loss2: 0.6299, train loss3: 0.1943, train mpjpe1: 94.9709, train mpjpe2: 100.6808
[2025-10-17 03:18:02] Epoch: 17,   val loss1: 0.1736,   val loss2: 0.6290,   val loss3: 0.1820,   val mpjpe1: 93.2534,   val mpjpe2: 98.2820
[2025-10-17 03:27:33] Epoch: 18, train loss1: 0.1789, train loss2: 0.6314, train loss3: 0.1904, train mpjpe1: 92.0509, train mpjpe2: 98.1822
[2025-10-17 03:27:33] Epoch: 18,   val loss1: 0.1733,   val loss2: 0.6284,   val loss3: 0.1832,   val mpjpe1: 94.0646,   val mpjpe2: 96.8764
[2025-10-17 03:37:12] Epoch: 19, train loss1: 0.1692, train loss2: 0.6296, train loss3: 0.1812, train mpjpe1: 88.3272, train mpjpe2: 94.7059
[2025-10-17 03:37:12] Epoch: 19,   val loss1: 0.1724,   val loss2: nan,   val loss3: nan,   val mpjpe1: 94.2306,   val mpjpe2: nan
[2025-10-17 03:46:50] Epoch: 20, train loss1: 0.1653, train loss2: 0.6292, train loss3: 0.1766, train mpjpe1: 86.7181, train mpjpe2: 92.6469
[2025-10-17 03:46:50] Epoch: 20,   val loss1: 0.1656,   val loss2: 0.6284,   val loss3: 0.1768,   val mpjpe1: 87.8114,   val mpjpe2: 90.9767
[2025-10-17 03:56:25] Epoch: 21, train loss1: 0.1657, train loss2: 0.6293, train loss3: 0.1772, train mpjpe1: 87.1802, train mpjpe2: 93.0086
[2025-10-17 03:56:25] Epoch: 21,   val loss1: 0.1804,   val loss2: 0.6284,   val loss3: 0.1892,   val mpjpe1: 99.0638,   val mpjpe2: 99.6446
[2025-10-17 04:06:05] Epoch: 22, train loss1: 0.1764, train loss2: 0.6295, train loss3: 0.1879, train mpjpe1: 91.1188, train mpjpe2: 97.3692
[2025-10-17 04:06:05] Epoch: 22,   val loss1: 0.1722,   val loss2: 0.6280,   val loss3: 0.1801,   val mpjpe1: 89.4211,   val mpjpe2: 92.9154
[2025-10-17 04:15:38] Epoch: 23, train loss1: 0.1652, train loss2: 0.6291, train loss3: 0.1761, train mpjpe1: 87.4491, train mpjpe2: 93.7162
[2025-10-17 04:15:38] Epoch: 23,   val loss1: 0.1679,   val loss2: 0.6282,   val loss3: 0.1772,   val mpjpe1: 91.6700,   val mpjpe2: 94.9566
[2025-10-17 04:25:25] Epoch: 24, train loss1: 0.1665, train loss2: 0.6293, train loss3: 0.1786, train mpjpe1: 87.6260, train mpjpe2: 93.7204
[2025-10-17 04:25:25] Epoch: 24,   val loss1: 0.1711,   val loss2: 0.6279,   val loss3: 0.1821,   val mpjpe1: 94.6093,   val mpjpe2: 96.8487
[2025-10-17 04:35:02] Epoch: 25, train loss1: 0.1657, train loss2: 0.6293, train loss3: 0.1767, train mpjpe1: 87.1770, train mpjpe2: 92.9510
[2025-10-17 04:35:02] Epoch: 25,   val loss1: 0.1723,   val loss2: 0.6280,   val loss3: 0.1831,   val mpjpe1: 95.4432,   val mpjpe2: 100.8822
[2025-10-17 04:44:46] Epoch: 26, train loss1: 0.1662, train loss2: 0.6294, train loss3: 0.1773, train mpjpe1: 87.3953, train mpjpe2: 93.2717
[2025-10-17 04:44:46] Epoch: 26,   val loss1: 0.1820,   val loss2: nan,   val loss3: nan,   val mpjpe1: 103.6728,   val mpjpe2: nan
[2025-10-17 04:54:29] Epoch: 27, train loss1: 0.1633, train loss2: 0.6291, train loss3: 0.1746, train mpjpe1: 86.2641, train mpjpe2: 92.0061
[2025-10-17 04:54:29] Epoch: 27,   val loss1: 0.1685,   val loss2: 0.6279,   val loss3: 0.1768,   val mpjpe1: 94.2769,   val mpjpe2: 94.1493
[2025-10-17 05:04:05] Epoch: 28, train loss1: 0.1576, train loss2: 0.6290, train loss3: 0.1685, train mpjpe1: 83.6597, train mpjpe2: 89.7434
[2025-10-17 05:04:05] Epoch: 28,   val loss1: 0.1635,   val loss2: 0.6278,   val loss3: 0.1733,   val mpjpe1: 86.9628,   val mpjpe2: 89.8175
[2025-10-17 05:13:52] Epoch: 29, train loss1: 0.1551, train loss2: 0.6295, train loss3: 0.1663, train mpjpe1: 83.1082, train mpjpe2: 89.0259
[2025-10-17 05:13:52] Epoch: 29,   val loss1: 0.1671,   val loss2: 0.6283,   val loss3: 0.1773,   val mpjpe1: 94.8839,   val mpjpe2: 96.0680
[2025-10-17 05:23:39] Epoch: 30, train loss1: 0.1565, train loss2: 0.6292, train loss3: 0.1684, train mpjpe1: 84.1009, train mpjpe2: 90.1319
[2025-10-17 05:23:39] Epoch: 30,   val loss1: 0.1630,   val loss2: 0.6278,   val loss3: 0.1725,   val mpjpe1: 87.7037,   val mpjpe2: 89.6320
[2025-10-17 05:33:28] Epoch: 31, train loss1: 0.1543, train loss2: 0.6290, train loss3: 0.1657, train mpjpe1: 83.9116, train mpjpe2: 89.9002
[2025-10-17 05:33:28] Epoch: 31,   val loss1: 0.1591,   val loss2: nan,   val loss3: nan,   val mpjpe1: 92.4934,   val mpjpe2: nan
[2025-10-17 05:43:18] Epoch: 32, train loss1: 0.1544, train loss2: 0.6291, train loss3: 0.1661, train mpjpe1: 83.7893, train mpjpe2: 89.6080
[2025-10-17 05:43:18] Epoch: 32,   val loss1: 0.1567,   val loss2: nan,   val loss3: nan,   val mpjpe1: 87.2338,   val mpjpe2: nan
[2025-10-17 05:53:01] Epoch: 33, train loss1: 0.1632, train loss2: 0.6290, train loss3: 0.1748, train mpjpe1: 87.1889, train mpjpe2: 93.0683
[2025-10-17 05:53:01] Epoch: 33,   val loss1: 0.1635,   val loss2: 0.6280,   val loss3: 0.1742,   val mpjpe1: 91.6509,   val mpjpe2: 93.2409
[2025-10-17 06:02:47] Epoch: 34, train loss1: 0.1569, train loss2: 0.6289, train loss3: 0.1681, train mpjpe1: 84.9573, train mpjpe2: 90.6491
[2025-10-17 06:02:47] Epoch: 34,   val loss1: 0.1555,   val loss2: 0.6279,   val loss3: 0.1656,   val mpjpe1: 83.9447,   val mpjpe2: 86.7140
[2025-10-17 06:12:34] Epoch: 35, train loss1: 0.1533, train loss2: 0.6294, train loss3: 0.1643, train mpjpe1: 82.6658, train mpjpe2: 88.6878
[2025-10-17 06:12:34] Epoch: 35,   val loss1: 0.1645,   val loss2: nan,   val loss3: nan,   val mpjpe1: 91.8048,   val mpjpe2: nan
[2025-10-17 06:22:14] Epoch: 36, train loss1: 0.1564, train loss2: 0.6294, train loss3: 0.1675, train mpjpe1: 83.8297, train mpjpe2: 89.6946
[2025-10-17 06:22:14] Epoch: 36,   val loss1: 0.1633,   val loss2: 0.6286,   val loss3: 0.1707,   val mpjpe1: 90.0077,   val mpjpe2: 90.5271
[2025-10-17 06:31:51] Epoch: 37, train loss1: 0.1599, train loss2: 0.6292, train loss3: 0.1716, train mpjpe1: 84.9042, train mpjpe2: 91.0788
[2025-10-17 06:31:51] Epoch: 37,   val loss1: 0.1657,   val loss2: 0.6277,   val loss3: 0.1732,   val mpjpe1: 91.7561,   val mpjpe2: 91.9694
[2025-10-17 06:41:32] Epoch: 38, train loss1: 0.1666, train loss2: 0.6292, train loss3: 0.1772, train mpjpe1: 89.3871, train mpjpe2: 94.9442
[2025-10-17 06:41:32] Epoch: 38,   val loss1: 0.1635,   val loss2: 0.6312,   val loss3: 0.1735,   val mpjpe1: 89.9666,   val mpjpe2: 91.6660
[2025-10-17 06:51:14] Epoch: 39, train loss1: 0.1705, train loss2: 0.6312, train loss3: 0.1817, train mpjpe1: 91.5944, train mpjpe2: 97.4698
[2025-10-17 06:51:14] Epoch: 39,   val loss1: 0.1683,   val loss2: nan,   val loss3: nan,   val mpjpe1: 97.3492,   val mpjpe2: nan
[2025-10-17 07:00:53] Epoch: 40, train loss1: 0.1580, train loss2: 0.6292, train loss3: 0.1691, train mpjpe1: 87.6171, train mpjpe2: 92.9664
[2025-10-17 07:00:53] Epoch: 40,   val loss1: 0.1648,   val loss2: 0.6281,   val loss3: 0.1709,   val mpjpe1: 99.6681,   val mpjpe2: 97.9696
[2025-10-17 07:10:28] Epoch: 41, train loss1: 0.1534, train loss2: 0.6294, train loss3: 0.1642, train mpjpe1: 86.2975, train mpjpe2: 91.1842
[2025-10-17 07:10:28] Epoch: 41,   val loss1: 0.1724,   val loss2: nan,   val loss3: nan,   val mpjpe1: 110.2210,   val mpjpe2: nan
[2025-10-17 07:20:04] Epoch: 42, train loss1: 0.1520, train loss2: 0.6289, train loss3: 0.1626, train mpjpe1: 85.0820, train mpjpe2: 90.0076
[2025-10-17 07:20:04] Epoch: 42,   val loss1: 0.1764,   val loss2: 0.6277,   val loss3: 0.1790,   val mpjpe1: 105.1898,   val mpjpe2: 101.3718
[2025-10-17 07:29:34] Epoch: 43, train loss1: 0.1540, train loss2: 0.6290, train loss3: 0.1651, train mpjpe1: 86.0367, train mpjpe2: 91.3030
[2025-10-17 07:29:34] Epoch: 43,   val loss1: 0.1684,   val loss2: 0.6280,   val loss3: 0.1735,   val mpjpe1: 96.1216,   val mpjpe2: 92.9481
[2025-10-17 07:39:13] Epoch: 44, train loss1: 0.1549, train loss2: 0.6291, train loss3: 0.1657, train mpjpe1: 83.9854, train mpjpe2: 90.1231
[2025-10-17 07:39:13] Epoch: 44,   val loss1: 0.1655,   val loss2: nan,   val loss3: nan,   val mpjpe1: 95.9402,   val mpjpe2: nan
[2025-10-17 07:48:55] Epoch: 45, train loss1: 0.1495, train loss2: 0.6288, train loss3: 0.1604, train mpjpe1: 82.8841, train mpjpe2: 88.7332
[2025-10-17 07:48:55] Epoch: 45,   val loss1: 0.1592,   val loss2: nan,   val loss3: nan,   val mpjpe1: 94.2674,   val mpjpe2: nan
[2025-10-17 07:58:28] Epoch: 46, train loss1: 0.1477, train loss2: 0.6289, train loss3: 0.1585, train mpjpe1: 83.0368, train mpjpe2: 88.5846
[2025-10-17 07:58:28] Epoch: 46,   val loss1: 0.1789,   val loss2: nan,   val loss3: nan,   val mpjpe1: 114.3782,   val mpjpe2: nan
[2025-10-17 08:08:01] Epoch: 47, train loss1: 0.1494, train loss2: 0.6291, train loss3: 0.1598, train mpjpe1: 83.2916, train mpjpe2: 88.9543
[2025-10-17 08:08:01] Epoch: 47,   val loss1: 0.1579,   val loss2: nan,   val loss3: nan,   val mpjpe1: 93.0474,   val mpjpe2: nan
[2025-10-17 08:17:46] Epoch: 48, train loss1: 0.1449, train loss2: 0.6289, train loss3: 0.1549, train mpjpe1: 81.3925, train mpjpe2: 86.9938
[2025-10-17 08:17:46] Epoch: 48,   val loss1: 0.1573,   val loss2: nan,   val loss3: nan,   val mpjpe1: 92.3989,   val mpjpe2: nan
[2025-10-17 08:27:26] Epoch: 49, train loss1: 0.1430, train loss2: 0.6289, train loss3: 0.1536, train mpjpe1: 80.3758, train mpjpe2: 86.1798
[2025-10-17 08:27:26] Epoch: 49,   val loss1: 0.1534,   val loss2: nan,   val loss3: nan,   val mpjpe1: 90.0991,   val mpjpe2: nan
[2025-10-17 08:37:07] Epoch: 50, train loss1: 0.1417, train loss2: 0.6290, train loss3: 0.1519, train mpjpe1: 80.1986, train mpjpe2: 85.4437
[2025-10-17 08:37:07] Epoch: 50,   val loss1: 0.1532,   val loss2: nan,   val loss3: nan,   val mpjpe1: 88.8571,   val mpjpe2: nan
[2025-10-17 08:46:47] Epoch: 51, train loss1: 0.1425, train loss2: 0.6287, train loss3: 0.1528, train mpjpe1: 80.8575, train mpjpe2: 86.0762
[2025-10-17 08:46:47] Epoch: 51,   val loss1: 0.1592,   val loss2: 0.6277,   val loss3: 0.1644,   val mpjpe1: 95.7796,   val mpjpe2: 93.6985
[2025-10-17 08:56:41] Epoch: 52, train loss1: 0.1420, train loss2: 0.6287, train loss3: 0.1522, train mpjpe1: 80.9188, train mpjpe2: 86.2956
[2025-10-17 08:56:41] Epoch: 52,   val loss1: 0.1576,   val loss2: nan,   val loss3: nan,   val mpjpe1: 97.6345,   val mpjpe2: nan
[2025-10-17 09:06:28] Epoch: 53, train loss1: 0.1389, train loss2: 0.6289, train loss3: 0.1492, train mpjpe1: 79.6755, train mpjpe2: 85.0286
[2025-10-17 09:06:28] Epoch: 53,   val loss1: 0.1604,   val loss2: nan,   val loss3: nan,   val mpjpe1: 100.4295,   val mpjpe2: nan
[2025-10-17 09:16:14] Epoch: 54, train loss1: 0.1386, train loss2: 0.6289, train loss3: 0.1486, train mpjpe1: 79.3864, train mpjpe2: 84.4791
[2025-10-17 09:16:14] Epoch: 54,   val loss1: 0.1486,   val loss2: 0.6277,   val loss3: 0.1560,   val mpjpe1: 86.1369,   val mpjpe2: 86.4813
[2025-10-17 09:25:58] Epoch: 55, train loss1: 0.1367, train loss2: 0.6289, train loss3: 0.1470, train mpjpe1: 78.7942, train mpjpe2: 84.0290
[2025-10-17 09:25:58] Epoch: 55,   val loss1: 0.1562,   val loss2: nan,   val loss3: nan,   val mpjpe1: 94.5017,   val mpjpe2: nan
[2025-10-17 09:35:40] Epoch: 56, train loss1: 0.1363, train loss2: 0.6289, train loss3: 0.1465, train mpjpe1: 78.3711, train mpjpe2: 83.9584
[2025-10-17 09:35:40] Epoch: 56,   val loss1: 0.1524,   val loss2: nan,   val loss3: nan,   val mpjpe1: 92.1662,   val mpjpe2: nan
