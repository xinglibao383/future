[2025-10-17 17:25:50] 备注: 使用场景1、场景2、场景3数据, 对transformer调参
[2025-10-17 17:25:50] mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, lstm_hidden=128, lstm_layers=2, lstm_dropout=0.1, gru_hidden=128, gru_layers=2, gru_dropout=0.1, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=15, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-17 17:30:15] [20251017172550] Epoch: 0, train loss1: 0.2888, train loss2: 0.6001, train loss3: 0.3065, train mpjpe1: 136.0793, train mpjpe2: 150.1329
[2025-10-17 17:30:15] [20251017172550] Epoch: 0,   val loss1: 0.2436,   val loss2: 0.5309,   val loss3: 0.2592,   val mpjpe1: 121.5397,   val mpjpe2: 127.3833
[2025-10-17 17:34:42] [20251017172550] Epoch: 1, train loss1: 0.2427, train loss2: 0.5314, train loss3: 0.2540, train mpjpe1: 116.3777, train mpjpe2: 121.8642
[2025-10-17 17:34:42] [20251017172550] Epoch: 1,   val loss1: 0.2443,   val loss2: 0.5116,   val loss3: 0.2551,   val mpjpe1: 121.4701,   val mpjpe2: 113.6601
[2025-10-17 17:39:06] [20251017172550] Epoch: 2, train loss1: 0.2329, train loss2: 0.5126, train loss3: 0.2447, train mpjpe1: 110.4723, train mpjpe2: 114.7536
[2025-10-17 17:39:06] [20251017172550] Epoch: 2,   val loss1: 0.2308,   val loss2: 0.5005,   val loss3: 0.2377,   val mpjpe1: 109.5485,   val mpjpe2: 111.5031
[2025-10-17 17:43:30] [20251017172550] Epoch: 3, train loss1: 0.2250, train loss2: 0.5034, train loss3: 0.2359, train mpjpe1: 105.5858, train mpjpe2: 110.8262
[2025-10-17 17:43:30] [20251017172550] Epoch: 3,   val loss1: 0.2153,   val loss2: 0.4879,   val loss3: 0.2258,   val mpjpe1: 101.9361,   val mpjpe2: 111.9819
[2025-10-17 17:47:55] [20251017172550] Epoch: 4, train loss1: 0.2235, train loss2: 0.4970, train loss3: 0.2362, train mpjpe1: 104.8911, train mpjpe2: 111.5210
[2025-10-17 17:47:55] [20251017172550] Epoch: 4,   val loss1: 0.2387,   val loss2: 0.4862,   val loss3: 0.2535,   val mpjpe1: 107.3885,   val mpjpe2: 117.1202
[2025-10-17 17:52:22] [20251017172550] Epoch: 5, train loss1: 0.2256, train loss2: 0.4862, train loss3: 0.2379, train mpjpe1: 104.9838, train mpjpe2: 111.4444
[2025-10-17 17:52:22] [20251017172550] Epoch: 5,   val loss1: 0.2220,   val loss2: 0.4712,   val loss3: 0.2358,   val mpjpe1: 103.9190,   val mpjpe2: 114.7494
[2025-10-17 17:56:48] [20251017172550] Epoch: 6, train loss1: 0.2151, train loss2: 0.4738, train loss3: 0.2272, train mpjpe1: 101.8733, train mpjpe2: 108.7810
[2025-10-17 17:56:48] [20251017172550] Epoch: 6,   val loss1: 0.2103,   val loss2: 0.4620,   val loss3: 0.2341,   val mpjpe1: 100.4021,   val mpjpe2: 112.3614
[2025-10-17 18:01:11] [20251017172550] Epoch: 7, train loss1: 0.2100, train loss2: 0.4674, train loss3: 0.2225, train mpjpe1: 100.1898, train mpjpe2: 107.2137
[2025-10-17 18:01:11] [20251017172550] Epoch: 7,   val loss1: 0.2186,   val loss2: 0.4556,   val loss3: 0.2453,   val mpjpe1: 101.5348,   val mpjpe2: 112.7329
[2025-10-17 18:05:38] [20251017172550] Epoch: 8, train loss1: 0.2131, train loss2: 0.4643, train loss3: 0.2262, train mpjpe1: 100.9326, train mpjpe2: 107.7355
[2025-10-17 18:05:38] [20251017172550] Epoch: 8,   val loss1: 0.2107,   val loss2: 0.4527,   val loss3: 0.2293,   val mpjpe1: 100.7983,   val mpjpe2: 109.1853
[2025-10-17 18:10:04] [20251017172550] Epoch: 9, train loss1: 0.2074, train loss2: 0.4580, train loss3: 0.2197, train mpjpe1: 100.2146, train mpjpe2: 106.6067
[2025-10-17 18:10:04] [20251017172550] Epoch: 9,   val loss1: 0.2208,   val loss2: 0.4503,   val loss3: 0.2375,   val mpjpe1: 101.8271,   val mpjpe2: 107.9582
[2025-10-17 18:14:28] [20251017172550] Epoch: 10, train loss1: 0.2095, train loss2: 0.4543, train loss3: 0.2232, train mpjpe1: 99.8114, train mpjpe2: 106.3668
[2025-10-17 18:14:28] [20251017172550] Epoch: 10,   val loss1: 0.2076,   val loss2: 0.4480,   val loss3: 0.2236,   val mpjpe1: 99.5856,   val mpjpe2: 108.3664
[2025-10-17 18:19:33] [20251017172550] Epoch: 11, train loss1: 0.2050, train loss2: 0.4470, train loss3: 0.2181, train mpjpe1: 98.7612, train mpjpe2: 105.0424
[2025-10-17 18:19:33] [20251017172550] Epoch: 11,   val loss1: 0.1967,   val loss2: 0.4319,   val loss3: 0.2081,   val mpjpe1: 98.7964,   val mpjpe2: 102.3078
[2025-10-17 18:24:44] [20251017172550] Epoch: 12, train loss1: 0.1994, train loss2: 0.4424, train loss3: 0.2129, train mpjpe1: 97.2575, train mpjpe2: 104.0395
[2025-10-17 18:24:44] [20251017172550] Epoch: 12,   val loss1: 0.1948,   val loss2: 0.4304,   val loss3: 0.2079,   val mpjpe1: 94.7288,   val mpjpe2: 102.5890
[2025-10-17 18:29:55] [20251017172550] Epoch: 13, train loss1: 0.2060, train loss2: 0.4426, train loss3: 0.2194, train mpjpe1: 99.1962, train mpjpe2: 105.6872
[2025-10-17 18:29:55] [20251017172550] Epoch: 13,   val loss1: 0.1999,   val loss2: 0.4419,   val loss3: 0.2200,   val mpjpe1: 101.8583,   val mpjpe2: 114.9333
[2025-10-17 18:35:09] [20251017172550] Epoch: 14, train loss1: 0.1967, train loss2: 0.4375, train loss3: 0.2102, train mpjpe1: 97.0011, train mpjpe2: 103.5577
[2025-10-17 18:35:09] [20251017172550] Epoch: 14,   val loss1: 0.1950,   val loss2: 0.4242,   val loss3: 0.2102,   val mpjpe1: 97.0404,   val mpjpe2: 104.4507
[2025-10-17 18:40:19] [20251017172550] Epoch: 15, train loss1: 0.1946, train loss2: 0.4301, train loss3: 0.2077, train mpjpe1: 96.0594, train mpjpe2: 102.3351
[2025-10-17 18:40:19] [20251017172550] Epoch: 15,   val loss1: 0.1894,   val loss2: 0.4170,   val loss3: 0.2034,   val mpjpe1: 93.4048,   val mpjpe2: 99.7178
[2025-10-17 18:45:31] [20251017172550] Epoch: 16, train loss1: 0.1917, train loss2: 0.4241, train loss3: 0.2059, train mpjpe1: 95.1106, train mpjpe2: 102.4844
[2025-10-17 18:45:31] [20251017172550] Epoch: 16,   val loss1: 0.1879,   val loss2: 0.4115,   val loss3: 0.2000,   val mpjpe1: 94.8898,   val mpjpe2: 99.9321
[2025-10-17 18:50:47] [20251017172550] Epoch: 17, train loss1: 0.1900, train loss2: 0.4214, train loss3: 0.2044, train mpjpe1: 94.4428, train mpjpe2: 101.7061
[2025-10-17 18:50:47] [20251017172550] Epoch: 17,   val loss1: 0.1898,   val loss2: 0.4240,   val loss3: 0.2100,   val mpjpe1: 95.3439,   val mpjpe2: 103.3877
[2025-10-17 18:56:02] [20251017172550] Epoch: 18, train loss1: 0.1897, train loss2: 0.4223, train loss3: 0.2044, train mpjpe1: 94.8963, train mpjpe2: 102.0210
[2025-10-17 18:56:02] [20251017172550] Epoch: 18,   val loss1: 0.1889,   val loss2: 0.4083,   val loss3: 0.2009,   val mpjpe1: 94.2887,   val mpjpe2: 100.4346
[2025-10-17 19:01:14] [20251017172550] Epoch: 19, train loss1: 0.1880, train loss2: 0.4159, train loss3: 0.2026, train mpjpe1: 93.8868, train mpjpe2: 100.7943
[2025-10-17 19:01:14] [20251017172550] Epoch: 19,   val loss1: 0.1833,   val loss2: 0.4028,   val loss3: 0.1988,   val mpjpe1: 94.2041,   val mpjpe2: 101.9240
[2025-10-17 19:06:29] [20251017172550] Epoch: 20, train loss1: 0.1817, train loss2: 0.4075, train loss3: 0.1954, train mpjpe1: 91.8196, train mpjpe2: 98.9753
[2025-10-17 19:06:29] [20251017172550] Epoch: 20,   val loss1: 0.1811,   val loss2: 0.3960,   val loss3: 0.1959,   val mpjpe1: 93.5982,   val mpjpe2: 102.3453
[2025-10-17 19:11:55] [20251017172550] Epoch: 21, train loss1: 0.1820, train loss2: 0.4102, train loss3: 0.1972, train mpjpe1: 91.8926, train mpjpe2: 99.4032
[2025-10-17 19:11:55] [20251017172550] Epoch: 21,   val loss1: 0.1804,   val loss2: 0.4034,   val loss3: 0.1965,   val mpjpe1: 91.0290,   val mpjpe2: 100.2524
[2025-10-17 19:17:17] [20251017172550] Epoch: 22, train loss1: 0.1799, train loss2: 0.4086, train loss3: 0.1951, train mpjpe1: 91.3584, train mpjpe2: 98.9295
[2025-10-17 19:17:17] [20251017172550] Epoch: 22,   val loss1: 0.1892,   val loss2: 0.4012,   val loss3: 0.2041,   val mpjpe1: 94.3921,   val mpjpe2: 100.5093
[2025-10-17 19:22:50] [20251017172550] Epoch: 23, train loss1: 0.1803, train loss2: 0.4034, train loss3: 0.1944, train mpjpe1: 90.9860, train mpjpe2: 98.1172
[2025-10-17 19:22:50] [20251017172550] Epoch: 23,   val loss1: 0.1796,   val loss2: 0.3953,   val loss3: 0.1932,   val mpjpe1: 91.0504,   val mpjpe2: 97.4335
