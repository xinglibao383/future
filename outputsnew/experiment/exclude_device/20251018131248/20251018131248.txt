[2025-10-18 13:12:48] 备注: 设备消融实验, exclude_device_idx = 0
[2025-10-18 13:12:48] exclude_device_idx=0, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:21:43] [20251018131248] Epoch: 0, train loss1: 0.2683, train loss2: 0.5826, train loss3: 0.2764, train mpjpe1: 128.1922, train mpjpe2: 135.2335
[2025-10-18 13:21:43] [20251018131248] Epoch: 0,   val loss1: 0.2324,   val loss2: 0.5059,   val loss3: 0.2403,   val mpjpe1: 120.8499,   val mpjpe2: 126.2363
[2025-10-18 13:31:01] [20251018131248] Epoch: 1, train loss1: 0.2170, train loss2: 0.5008, train loss3: 0.2261, train mpjpe1: 105.9098, train mpjpe2: 112.4954
[2025-10-18 13:31:01] [20251018131248] Epoch: 1,   val loss1: 0.2001,   val loss2: 0.4680,   val loss3: 0.2098,   val mpjpe1: 102.3540,   val mpjpe2: 107.1572
[2025-10-18 13:40:20] [20251018131248] Epoch: 2, train loss1: 0.1981, train loss2: 0.4687, train loss3: 0.2089, train mpjpe1: 99.2704, train mpjpe2: 105.9630
[2025-10-18 13:40:20] [20251018131248] Epoch: 2,   val loss1: 0.1924,   val loss2: 0.4387,   val loss3: 0.1992,   val mpjpe1: 98.8390,   val mpjpe2: 104.2453
[2025-10-18 13:49:44] [20251018131248] Epoch: 3, train loss1: 0.1899, train loss2: 0.4374, train loss3: 0.2010, train mpjpe1: 96.0420, train mpjpe2: 102.7253
[2025-10-18 13:49:44] [20251018131248] Epoch: 3,   val loss1: 0.1850,   val loss2: 0.4122,   val loss3: 0.1957,   val mpjpe1: 92.9289,   val mpjpe2: 99.6630
[2025-10-18 13:59:01] [20251018131248] Epoch: 4, train loss1: 0.1801, train loss2: 0.4117, train loss3: 0.1916, train mpjpe1: 92.7765, train mpjpe2: 99.6641
[2025-10-18 13:59:01] [20251018131248] Epoch: 4,   val loss1: 0.1746,   val loss2: 0.3910,   val loss3: 0.1850,   val mpjpe1: 91.0521,   val mpjpe2: 97.6194
[2025-10-18 14:08:18] [20251018131248] Epoch: 5, train loss1: 0.1743, train loss2: 0.3956, train loss3: 0.1863, train mpjpe1: 90.7629, train mpjpe2: 97.8424
[2025-10-18 14:08:18] [20251018131248] Epoch: 5,   val loss1: 0.1736,   val loss2: 0.3817,   val loss3: 0.1838,   val mpjpe1: 90.5321,   val mpjpe2: 96.4118
[2025-10-18 14:17:34] [20251018131248] Epoch: 6, train loss1: 0.1714, train loss2: 0.3861, train loss3: 0.1834, train mpjpe1: 89.4454, train mpjpe2: 96.5109
[2025-10-18 14:17:34] [20251018131248] Epoch: 6,   val loss1: 0.1683,   val loss2: 0.3727,   val loss3: 0.1777,   val mpjpe1: 88.9641,   val mpjpe2: 94.4928
[2025-10-18 14:26:48] [20251018131248] Epoch: 7, train loss1: 0.1659, train loss2: 0.3791, train loss3: 0.1779, train mpjpe1: 87.7308, train mpjpe2: 94.4684
[2025-10-18 14:26:48] [20251018131248] Epoch: 7,   val loss1: 0.1709,   val loss2: 0.3699,   val loss3: 0.1814,   val mpjpe1: 89.5641,   val mpjpe2: 95.2995
[2025-10-18 14:36:09] [20251018131248] Epoch: 8, train loss1: 0.1622, train loss2: 0.3736, train loss3: 0.1740, train mpjpe1: 86.2679, train mpjpe2: 93.0620
[2025-10-18 14:36:09] [20251018131248] Epoch: 8,   val loss1: 0.1629,   val loss2: 0.3719,   val loss3: 0.1751,   val mpjpe1: 87.6735,   val mpjpe2: 95.1546
[2025-10-18 14:45:30] [20251018131248] Epoch: 9, train loss1: 0.1590, train loss2: 0.3702, train loss3: 0.1711, train mpjpe1: 84.7592, train mpjpe2: 91.7350
[2025-10-18 14:45:30] [20251018131248] Epoch: 9,   val loss1: 0.1569,   val loss2: 0.3633,   val loss3: 0.1675,   val mpjpe1: 86.1389,   val mpjpe2: 92.2820
[2025-10-18 14:54:53] [20251018131248] Epoch: 10, train loss1: 0.1567, train loss2: 0.3663, train loss3: 0.1686, train mpjpe1: 84.1601, train mpjpe2: 90.9133
[2025-10-18 14:54:53] [20251018131248] Epoch: 10,   val loss1: 0.1565,   val loss2: 0.3596,   val loss3: 0.1673,   val mpjpe1: 86.5405,   val mpjpe2: 93.1320
[2025-10-18 15:04:29] [20251018131248] Epoch: 11, train loss1: 0.1554, train loss2: 0.3641, train loss3: 0.1673, train mpjpe1: 83.4443, train mpjpe2: 90.3314
[2025-10-18 15:04:29] [20251018131248] Epoch: 11,   val loss1: 0.1586,   val loss2: 0.3598,   val loss3: 0.1691,   val mpjpe1: 86.8286,   val mpjpe2: 92.6657
[2025-10-18 15:13:42] [20251018131248] Epoch: 12, train loss1: 0.1521, train loss2: 0.3610, train loss3: 0.1638, train mpjpe1: 82.1155, train mpjpe2: 88.8408
[2025-10-18 15:13:42] [20251018131248] Epoch: 12,   val loss1: 0.1538,   val loss2: 0.3571,   val loss3: 0.1640,   val mpjpe1: 82.9813,   val mpjpe2: 90.0003
[2025-10-18 15:23:08] [20251018131248] Epoch: 13, train loss1: 0.1491, train loss2: 0.3573, train loss3: 0.1609, train mpjpe1: 80.9776, train mpjpe2: 87.8266
[2025-10-18 15:23:08] [20251018131248] Epoch: 13,   val loss1: 0.1529,   val loss2: 0.3508,   val loss3: 0.1633,   val mpjpe1: 81.9907,   val mpjpe2: 88.0751
[2025-10-18 15:32:19] [20251018131248] Epoch: 14, train loss1: 0.1466, train loss2: 0.3555, train loss3: 0.1585, train mpjpe1: 80.3726, train mpjpe2: 86.7876
[2025-10-18 15:32:19] [20251018131248] Epoch: 14,   val loss1: 0.1538,   val loss2: 0.3524,   val loss3: 0.1641,   val mpjpe1: 84.1223,   val mpjpe2: 90.9205
