[2025-10-18 13:14:24] 备注: 设备消融实验, exclude_device_idx = 0
[2025-10-18 13:14:24] exclude_device_idx=0, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:23:28] [20251018131424] Epoch: 0, train loss1: 0.2661, train loss2: 0.5887, train loss3: 0.2748, train mpjpe1: 128.1022, train mpjpe2: 135.4680
[2025-10-18 13:23:28] [20251018131424] Epoch: 0,   val loss1: 0.2296,   val loss2: 0.5110,   val loss3: 0.2393,   val mpjpe1: 117.2649,   val mpjpe2: 121.4853
[2025-10-18 13:32:51] [20251018131424] Epoch: 1, train loss1: 0.2144, train loss2: 0.5056, train loss3: 0.2238, train mpjpe1: 105.3156, train mpjpe2: 111.5648
[2025-10-18 13:32:51] [20251018131424] Epoch: 1,   val loss1: 0.2067,   val loss2: 0.4831,   val loss3: 0.2156,   val mpjpe1: 102.8004,   val mpjpe2: 105.8970
[2025-10-18 13:42:00] [20251018131424] Epoch: 2, train loss1: 0.1972, train loss2: 0.4737, train loss3: 0.2076, train mpjpe1: 98.7818, train mpjpe2: 105.0538
[2025-10-18 13:42:00] [20251018131424] Epoch: 2,   val loss1: 0.1945,   val loss2: 0.4520,   val loss3: 0.2043,   val mpjpe1: 101.4483,   val mpjpe2: 107.6159
[2025-10-18 13:51:06] [20251018131424] Epoch: 3, train loss1: 0.1865, train loss2: 0.4388, train loss3: 0.1977, train mpjpe1: 95.3606, train mpjpe2: 102.1795
[2025-10-18 13:51:06] [20251018131424] Epoch: 3,   val loss1: 0.1812,   val loss2: 0.4170,   val loss3: 0.1939,   val mpjpe1: 93.1706,   val mpjpe2: 99.2239
[2025-10-18 14:00:29] [20251018131424] Epoch: 4, train loss1: 0.1794, train loss2: 0.4107, train loss3: 0.1912, train mpjpe1: 93.4724, train mpjpe2: 100.3973
[2025-10-18 14:00:29] [20251018131424] Epoch: 4,   val loss1: 0.1771,   val loss2: 0.3929,   val loss3: 0.1900,   val mpjpe1: 96.6316,   val mpjpe2: 103.9358
[2025-10-18 14:09:42] [20251018131424] Epoch: 5, train loss1: 0.1740, train loss2: 0.3942, train loss3: 0.1859, train mpjpe1: 91.1515, train mpjpe2: 98.2583
[2025-10-18 14:09:42] [20251018131424] Epoch: 5,   val loss1: 0.1823,   val loss2: 0.3817,   val loss3: 0.1921,   val mpjpe1: 103.0972,   val mpjpe2: 106.6460
[2025-10-18 14:19:02] [20251018131424] Epoch: 6, train loss1: 0.1702, train loss2: 0.3847, train loss3: 0.1821, train mpjpe1: 89.4382, train mpjpe2: 96.1672
[2025-10-18 14:19:02] [20251018131424] Epoch: 6,   val loss1: 0.1676,   val loss2: 0.3802,   val loss3: 0.1798,   val mpjpe1: 89.0142,   val mpjpe2: 95.5529
[2025-10-18 14:28:23] [20251018131424] Epoch: 7, train loss1: 0.1653, train loss2: 0.3791, train loss3: 0.1777, train mpjpe1: 87.7419, train mpjpe2: 94.5598
[2025-10-18 14:28:23] [20251018131424] Epoch: 7,   val loss1: 0.1664,   val loss2: 0.3679,   val loss3: 0.1777,   val mpjpe1: 89.9939,   val mpjpe2: 96.9709
[2025-10-18 14:37:29] [20251018131424] Epoch: 8, train loss1: 0.1615, train loss2: 0.3730, train loss3: 0.1738, train mpjpe1: 86.4057, train mpjpe2: 93.2250
[2025-10-18 14:37:29] [20251018131424] Epoch: 8,   val loss1: 0.1595,   val loss2: 0.3666,   val loss3: 0.1713,   val mpjpe1: 85.1923,   val mpjpe2: 91.2127
[2025-10-18 14:46:39] [20251018131424] Epoch: 9, train loss1: 0.1589, train loss2: 0.3685, train loss3: 0.1709, train mpjpe1: 85.3544, train mpjpe2: 92.1396
[2025-10-18 14:46:39] [20251018131424] Epoch: 9,   val loss1: 0.1598,   val loss2: 0.3682,   val loss3: 0.1724,   val mpjpe1: 85.6242,   val mpjpe2: 91.9392
[2025-10-18 14:55:56] [20251018131424] Epoch: 10, train loss1: 0.1562, train loss2: 0.3656, train loss3: 0.1681, train mpjpe1: 84.0046, train mpjpe2: 90.6739
[2025-10-18 14:55:56] [20251018131424] Epoch: 10,   val loss1: 0.1554,   val loss2: 0.3637,   val loss3: 0.1681,   val mpjpe1: 85.4671,   val mpjpe2: 92.4678
[2025-10-18 15:05:29] [20251018131424] Epoch: 11, train loss1: 0.1540, train loss2: 0.3634, train loss3: 0.1662, train mpjpe1: 83.3707, train mpjpe2: 90.2218
[2025-10-18 15:05:29] [20251018131424] Epoch: 11,   val loss1: 0.1571,   val loss2: 0.3625,   val loss3: 0.1695,   val mpjpe1: 87.8434,   val mpjpe2: 93.4150
[2025-10-18 15:14:50] [20251018131424] Epoch: 12, train loss1: 0.1535, train loss2: 0.3616, train loss3: 0.1658, train mpjpe1: 83.2048, train mpjpe2: 89.8462
[2025-10-18 15:14:50] [20251018131424] Epoch: 12,   val loss1: 0.1537,   val loss2: 0.3567,   val loss3: 0.1648,   val mpjpe1: 84.6438,   val mpjpe2: 90.6669
[2025-10-18 15:23:59] [20251018131424] Epoch: 13, train loss1: 0.1484, train loss2: 0.3565, train loss3: 0.1602, train mpjpe1: 81.1274, train mpjpe2: 87.7027
[2025-10-18 15:23:59] [20251018131424] Epoch: 13,   val loss1: 0.1534,   val loss2: 0.3524,   val loss3: 0.1649,   val mpjpe1: 83.2809,   val mpjpe2: 89.6702
[2025-10-18 15:33:15] [20251018131424] Epoch: 14, train loss1: 0.1479, train loss2: 0.3557, train loss3: 0.1596, train mpjpe1: 80.7178, train mpjpe2: 87.6393
[2025-10-18 15:33:15] [20251018131424] Epoch: 14,   val loss1: 0.1488,   val loss2: 0.3507,   val loss3: 0.1597,   val mpjpe1: 82.0816,   val mpjpe2: 88.0643
[2025-10-18 15:42:18] [20251018131424] Epoch: 15, train loss1: 0.1446, train loss2: 0.3521, train loss3: 0.1562, train mpjpe1: 79.5192, train mpjpe2: 86.1897
[2025-10-18 15:42:18] [20251018131424] Epoch: 15,   val loss1: 0.1493,   val loss2: 0.3546,   val loss3: 0.1622,   val mpjpe1: 82.3228,   val mpjpe2: 88.8976
[2025-10-18 15:51:29] [20251018131424] Epoch: 16, train loss1: 0.1423, train loss2: 0.3495, train loss3: 0.1534, train mpjpe1: 78.6588, train mpjpe2: 85.0756
[2025-10-18 15:51:29] [20251018131424] Epoch: 16,   val loss1: 0.1449,   val loss2: 0.3475,   val loss3: 0.1561,   val mpjpe1: 80.3656,   val mpjpe2: 86.2730
[2025-10-18 16:00:35] [20251018131424] Epoch: 17, train loss1: 0.1400, train loss2: 0.3479, train loss3: 0.1510, train mpjpe1: 77.8839, train mpjpe2: 84.0427
[2025-10-18 16:00:35] [20251018131424] Epoch: 17,   val loss1: 0.1459,   val loss2: 0.3484,   val loss3: 0.1566,   val mpjpe1: 81.9351,   val mpjpe2: 88.3482
[2025-10-18 16:09:44] [20251018131424] Epoch: 18, train loss1: 0.1394, train loss2: 0.3471, train loss3: 0.1508, train mpjpe1: 77.1462, train mpjpe2: 83.6212
[2025-10-18 16:09:44] [20251018131424] Epoch: 18,   val loss1: 0.1483,   val loss2: 0.3498,   val loss3: 0.1617,   val mpjpe1: 81.5102,   val mpjpe2: 88.0650
[2025-10-18 16:18:48] [20251018131424] Epoch: 19, train loss1: 0.1391, train loss2: 0.3464, train loss3: 0.1503, train mpjpe1: 77.2443, train mpjpe2: 83.6612
[2025-10-18 16:18:48] [20251018131424] Epoch: 19,   val loss1: 0.1415,   val loss2: 0.3477,   val loss3: 0.1528,   val mpjpe1: 78.2683,   val mpjpe2: 84.1990
[2025-10-18 16:28:04] [20251018131424] Epoch: 20, train loss1: 0.1376, train loss2: 0.3448, train loss3: 0.1488, train mpjpe1: 76.8253, train mpjpe2: 83.2387
[2025-10-18 16:28:04] [20251018131424] Epoch: 20,   val loss1: 0.1483,   val loss2: 0.3474,   val loss3: 0.1591,   val mpjpe1: 84.8930,   val mpjpe2: 91.5325
[2025-10-18 16:37:12] [20251018131424] Epoch: 21, train loss1: 0.1343, train loss2: 0.3429, train loss3: 0.1453, train mpjpe1: 75.2439, train mpjpe2: 81.6969
[2025-10-18 16:37:12] [20251018131424] Epoch: 21,   val loss1: 0.1398,   val loss2: 0.3431,   val loss3: 0.1502,   val mpjpe1: 80.0774,   val mpjpe2: 85.1016
[2025-10-18 16:45:59] [20251018131424] Epoch: 22, train loss1: 0.1324, train loss2: 0.3399, train loss3: 0.1435, train mpjpe1: 74.5180, train mpjpe2: 81.0839
[2025-10-18 16:45:59] [20251018131424] Epoch: 22,   val loss1: 0.1400,   val loss2: 0.3441,   val loss3: 0.1510,   val mpjpe1: 78.2323,   val mpjpe2: 84.2370
[2025-10-18 16:54:41] [20251018131424] Epoch: 23, train loss1: 0.1316, train loss2: 0.3384, train loss3: 0.1425, train mpjpe1: 73.9497, train mpjpe2: 80.4176
[2025-10-18 16:54:41] [20251018131424] Epoch: 23,   val loss1: 0.1394,   val loss2: 0.3401,   val loss3: 0.1501,   val mpjpe1: 78.9030,   val mpjpe2: 85.1087
[2025-10-18 17:03:26] [20251018131424] Epoch: 24, train loss1: 0.1295, train loss2: 0.3368, train loss3: 0.1403, train mpjpe1: 73.2132, train mpjpe2: 79.5211
[2025-10-18 17:03:26] [20251018131424] Epoch: 24,   val loss1: 0.1403,   val loss2: 0.3435,   val loss3: 0.1528,   val mpjpe1: 78.1899,   val mpjpe2: 84.7536
[2025-10-18 17:11:31] [20251018131424] Epoch: 25, train loss1: 0.1288, train loss2: 0.3366, train loss3: 0.1397, train mpjpe1: 72.8063, train mpjpe2: 79.2977
[2025-10-18 17:11:31] [20251018131424] Epoch: 25,   val loss1: 0.1392,   val loss2: 0.3407,   val loss3: 0.1507,   val mpjpe1: 77.5391,   val mpjpe2: 83.1657
[2025-10-18 17:19:19] [20251018131424] Epoch: 26, train loss1: 0.1281, train loss2: 0.3356, train loss3: 0.1392, train mpjpe1: 72.8698, train mpjpe2: 79.1329
[2025-10-18 17:19:19] [20251018131424] Epoch: 26,   val loss1: 0.1350,   val loss2: 0.3349,   val loss3: 0.1454,   val mpjpe1: 75.3688,   val mpjpe2: 81.2580
[2025-10-18 17:27:09] [20251018131424] Epoch: 27, train loss1: 0.1250, train loss2: 0.3337, train loss3: 0.1358, train mpjpe1: 71.2559, train mpjpe2: 77.5458
[2025-10-18 17:27:09] [20251018131424] Epoch: 27,   val loss1: 0.1346,   val loss2: 0.3360,   val loss3: 0.1451,   val mpjpe1: 76.1862,   val mpjpe2: 81.6676
[2025-10-18 17:34:52] [20251018131424] Epoch: 28, train loss1: 0.1249, train loss2: 0.3323, train loss3: 0.1354, train mpjpe1: 70.9246, train mpjpe2: 77.2703
[2025-10-18 17:34:52] [20251018131424] Epoch: 28,   val loss1: 0.1357,   val loss2: 0.3361,   val loss3: 0.1477,   val mpjpe1: 76.6264,   val mpjpe2: 83.8616
[2025-10-18 17:42:22] [20251018131424] Epoch: 29, train loss1: 0.1243, train loss2: 0.3324, train loss3: 0.1351, train mpjpe1: 70.6160, train mpjpe2: 76.8578
[2025-10-18 17:42:22] [20251018131424] Epoch: 29,   val loss1: 0.1381,   val loss2: 0.3378,   val loss3: 0.1510,   val mpjpe1: 75.9516,   val mpjpe2: 82.1665
[2025-10-18 17:49:25] [20251018131424] Epoch: 30, train loss1: 0.1221, train loss2: 0.3309, train loss3: 0.1323, train mpjpe1: 69.6666, train mpjpe2: 75.6480
[2025-10-18 17:49:25] [20251018131424] Epoch: 30,   val loss1: 0.1321,   val loss2: 0.3359,   val loss3: 0.1425,   val mpjpe1: 74.8005,   val mpjpe2: 80.7399
[2025-10-18 17:57:40] [20251018131424] Epoch: 31, train loss1: 0.1214, train loss2: 0.3308, train loss3: 0.1319, train mpjpe1: 69.0479, train mpjpe2: 75.3409
[2025-10-18 17:57:40] [20251018131424] Epoch: 31,   val loss1: 0.1306,   val loss2: 0.3322,   val loss3: 0.1406,   val mpjpe1: 73.7977,   val mpjpe2: 79.6317
[2025-10-18 18:06:23] [20251018131424] Epoch: 32, train loss1: 0.1217, train loss2: 0.3300, train loss3: 0.1323, train mpjpe1: 69.2223, train mpjpe2: 75.4694
[2025-10-18 18:06:23] [20251018131424] Epoch: 32,   val loss1: 0.1316,   val loss2: 0.3340,   val loss3: 0.1426,   val mpjpe1: 73.7342,   val mpjpe2: 79.9107
[2025-10-18 18:15:04] [20251018131424] Epoch: 33, train loss1: 0.1190, train loss2: 0.3287, train loss3: 0.1295, train mpjpe1: 67.9129, train mpjpe2: 73.9705
[2025-10-18 18:15:04] [20251018131424] Epoch: 33,   val loss1: 0.1289,   val loss2: 0.3323,   val loss3: 0.1396,   val mpjpe1: 72.4003,   val mpjpe2: 78.6110
[2025-10-18 18:23:43] [20251018131424] Epoch: 34, train loss1: 0.1167, train loss2: 0.3264, train loss3: 0.1268, train mpjpe1: 66.8414, train mpjpe2: 72.9378
[2025-10-18 18:23:43] [20251018131424] Epoch: 34,   val loss1: 0.1286,   val loss2: 0.3313,   val loss3: 0.1389,   val mpjpe1: 72.6836,   val mpjpe2: 78.4387
[2025-10-18 18:32:17] [20251018131424] Epoch: 35, train loss1: 0.1169, train loss2: 0.3273, train loss3: 0.1274, train mpjpe1: 66.8378, train mpjpe2: 73.2092
[2025-10-18 18:32:17] [20251018131424] Epoch: 35,   val loss1: 0.1298,   val loss2: 0.3327,   val loss3: 0.1405,   val mpjpe1: 73.7313,   val mpjpe2: 79.7210
[2025-10-18 18:40:52] [20251018131424] Epoch: 36, train loss1: 0.1161, train loss2: 0.3254, train loss3: 0.1264, train mpjpe1: 66.4096, train mpjpe2: 72.4491
[2025-10-18 18:40:52] [20251018131424] Epoch: 36,   val loss1: 0.1283,   val loss2: 0.3321,   val loss3: 0.1384,   val mpjpe1: 73.0429,   val mpjpe2: 78.9273
