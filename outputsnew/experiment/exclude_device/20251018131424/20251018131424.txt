[2025-10-18 13:14:24] 备注: 设备消融实验, exclude_device_idx = 0
[2025-10-18 13:14:24] exclude_device_idx=0, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:23:28] [20251018131424] Epoch: 0, train loss1: 0.2661, train loss2: 0.5887, train loss3: 0.2748, train mpjpe1: 128.1022, train mpjpe2: 135.4680
[2025-10-18 13:23:28] [20251018131424] Epoch: 0,   val loss1: 0.2296,   val loss2: 0.5110,   val loss3: 0.2393,   val mpjpe1: 117.2649,   val mpjpe2: 121.4853
[2025-10-18 13:32:51] [20251018131424] Epoch: 1, train loss1: 0.2144, train loss2: 0.5056, train loss3: 0.2238, train mpjpe1: 105.3156, train mpjpe2: 111.5648
[2025-10-18 13:32:51] [20251018131424] Epoch: 1,   val loss1: 0.2067,   val loss2: 0.4831,   val loss3: 0.2156,   val mpjpe1: 102.8004,   val mpjpe2: 105.8970
[2025-10-18 13:42:00] [20251018131424] Epoch: 2, train loss1: 0.1972, train loss2: 0.4737, train loss3: 0.2076, train mpjpe1: 98.7818, train mpjpe2: 105.0538
[2025-10-18 13:42:00] [20251018131424] Epoch: 2,   val loss1: 0.1945,   val loss2: 0.4520,   val loss3: 0.2043,   val mpjpe1: 101.4483,   val mpjpe2: 107.6159
[2025-10-18 13:51:06] [20251018131424] Epoch: 3, train loss1: 0.1865, train loss2: 0.4388, train loss3: 0.1977, train mpjpe1: 95.3606, train mpjpe2: 102.1795
[2025-10-18 13:51:06] [20251018131424] Epoch: 3,   val loss1: 0.1812,   val loss2: 0.4170,   val loss3: 0.1939,   val mpjpe1: 93.1706,   val mpjpe2: 99.2239
[2025-10-18 14:00:29] [20251018131424] Epoch: 4, train loss1: 0.1794, train loss2: 0.4107, train loss3: 0.1912, train mpjpe1: 93.4724, train mpjpe2: 100.3973
[2025-10-18 14:00:29] [20251018131424] Epoch: 4,   val loss1: 0.1771,   val loss2: 0.3929,   val loss3: 0.1900,   val mpjpe1: 96.6316,   val mpjpe2: 103.9358
[2025-10-18 14:09:42] [20251018131424] Epoch: 5, train loss1: 0.1740, train loss2: 0.3942, train loss3: 0.1859, train mpjpe1: 91.1515, train mpjpe2: 98.2583
[2025-10-18 14:09:42] [20251018131424] Epoch: 5,   val loss1: 0.1823,   val loss2: 0.3817,   val loss3: 0.1921,   val mpjpe1: 103.0972,   val mpjpe2: 106.6460
[2025-10-18 14:19:02] [20251018131424] Epoch: 6, train loss1: 0.1702, train loss2: 0.3847, train loss3: 0.1821, train mpjpe1: 89.4382, train mpjpe2: 96.1672
[2025-10-18 14:19:02] [20251018131424] Epoch: 6,   val loss1: 0.1676,   val loss2: 0.3802,   val loss3: 0.1798,   val mpjpe1: 89.0142,   val mpjpe2: 95.5529
[2025-10-18 14:28:23] [20251018131424] Epoch: 7, train loss1: 0.1653, train loss2: 0.3791, train loss3: 0.1777, train mpjpe1: 87.7419, train mpjpe2: 94.5598
[2025-10-18 14:28:23] [20251018131424] Epoch: 7,   val loss1: 0.1664,   val loss2: 0.3679,   val loss3: 0.1777,   val mpjpe1: 89.9939,   val mpjpe2: 96.9709
[2025-10-18 14:37:29] [20251018131424] Epoch: 8, train loss1: 0.1615, train loss2: 0.3730, train loss3: 0.1738, train mpjpe1: 86.4057, train mpjpe2: 93.2250
[2025-10-18 14:37:29] [20251018131424] Epoch: 8,   val loss1: 0.1595,   val loss2: 0.3666,   val loss3: 0.1713,   val mpjpe1: 85.1923,   val mpjpe2: 91.2127
[2025-10-18 14:46:39] [20251018131424] Epoch: 9, train loss1: 0.1589, train loss2: 0.3685, train loss3: 0.1709, train mpjpe1: 85.3544, train mpjpe2: 92.1396
[2025-10-18 14:46:39] [20251018131424] Epoch: 9,   val loss1: 0.1598,   val loss2: 0.3682,   val loss3: 0.1724,   val mpjpe1: 85.6242,   val mpjpe2: 91.9392
[2025-10-18 14:55:56] [20251018131424] Epoch: 10, train loss1: 0.1562, train loss2: 0.3656, train loss3: 0.1681, train mpjpe1: 84.0046, train mpjpe2: 90.6739
[2025-10-18 14:55:56] [20251018131424] Epoch: 10,   val loss1: 0.1554,   val loss2: 0.3637,   val loss3: 0.1681,   val mpjpe1: 85.4671,   val mpjpe2: 92.4678
[2025-10-18 15:05:29] [20251018131424] Epoch: 11, train loss1: 0.1540, train loss2: 0.3634, train loss3: 0.1662, train mpjpe1: 83.3707, train mpjpe2: 90.2218
[2025-10-18 15:05:29] [20251018131424] Epoch: 11,   val loss1: 0.1571,   val loss2: 0.3625,   val loss3: 0.1695,   val mpjpe1: 87.8434,   val mpjpe2: 93.4150
[2025-10-18 15:14:50] [20251018131424] Epoch: 12, train loss1: 0.1535, train loss2: 0.3616, train loss3: 0.1658, train mpjpe1: 83.2048, train mpjpe2: 89.8462
[2025-10-18 15:14:50] [20251018131424] Epoch: 12,   val loss1: 0.1537,   val loss2: 0.3567,   val loss3: 0.1648,   val mpjpe1: 84.6438,   val mpjpe2: 90.6669
[2025-10-18 15:23:59] [20251018131424] Epoch: 13, train loss1: 0.1484, train loss2: 0.3565, train loss3: 0.1602, train mpjpe1: 81.1274, train mpjpe2: 87.7027
[2025-10-18 15:23:59] [20251018131424] Epoch: 13,   val loss1: 0.1534,   val loss2: 0.3524,   val loss3: 0.1649,   val mpjpe1: 83.2809,   val mpjpe2: 89.6702
[2025-10-18 15:33:15] [20251018131424] Epoch: 14, train loss1: 0.1479, train loss2: 0.3557, train loss3: 0.1596, train mpjpe1: 80.7178, train mpjpe2: 87.6393
[2025-10-18 15:33:15] [20251018131424] Epoch: 14,   val loss1: 0.1488,   val loss2: 0.3507,   val loss3: 0.1597,   val mpjpe1: 82.0816,   val mpjpe2: 88.0643
[2025-10-18 15:42:18] [20251018131424] Epoch: 15, train loss1: 0.1446, train loss2: 0.3521, train loss3: 0.1562, train mpjpe1: 79.5192, train mpjpe2: 86.1897
[2025-10-18 15:42:18] [20251018131424] Epoch: 15,   val loss1: 0.1493,   val loss2: 0.3546,   val loss3: 0.1622,   val mpjpe1: 82.3228,   val mpjpe2: 88.8976
