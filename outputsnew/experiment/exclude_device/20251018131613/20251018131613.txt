[2025-10-18 13:16:13] 备注: 设备消融实验, exclude_device_idx = 1
[2025-10-18 13:16:13] exclude_device_idx=1, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:25:59] [20251018131613] Epoch: 0, train loss1: 0.2590, train loss2: 0.5901, train loss3: 0.2685, train mpjpe1: 119.8873, train mpjpe2: 126.3866
[2025-10-18 13:25:59] [20251018131613] Epoch: 0,   val loss1: 0.2127,   val loss2: 0.4988,   val loss3: 0.2224,   val mpjpe1: 106.5708,   val mpjpe2: 113.6882
[2025-10-18 13:35:36] [20251018131613] Epoch: 1, train loss1: 0.2054, train loss2: 0.4993, train loss3: 0.2149, train mpjpe1: 101.9966, train mpjpe2: 107.8078
[2025-10-18 13:35:36] [20251018131613] Epoch: 1,   val loss1: 0.2004,   val loss2: 0.4726,   val loss3: 0.2137,   val mpjpe1: 105.8360,   val mpjpe2: 112.2702
[2025-10-18 13:45:17] [20251018131613] Epoch: 2, train loss1: 0.1902, train loss2: 0.4684, train loss3: 0.2000, train mpjpe1: 97.2391, train mpjpe2: 102.8633
[2025-10-18 13:45:17] [20251018131613] Epoch: 2,   val loss1: 0.1909,   val loss2: 0.4452,   val loss3: 0.2005,   val mpjpe1: 102.0244,   val mpjpe2: 108.1176
[2025-10-18 13:54:53] [20251018131613] Epoch: 3, train loss1: 0.1808, train loss2: 0.4438, train loss3: 0.1912, train mpjpe1: 93.9480, train mpjpe2: 99.8710
[2025-10-18 13:54:53] [20251018131613] Epoch: 3,   val loss1: 0.1831,   val loss2: 0.4234,   val loss3: 0.1936,   val mpjpe1: 99.9045,   val mpjpe2: 106.0558
[2025-10-18 14:04:27] [20251018131613] Epoch: 4, train loss1: 0.1758, train loss2: 0.4220, train loss3: 0.1870, train mpjpe1: 91.8164, train mpjpe2: 98.0625
[2025-10-18 14:04:27] [20251018131613] Epoch: 4,   val loss1: 0.1734,   val loss2: 0.4019,   val loss3: 0.1838,   val mpjpe1: 98.9172,   val mpjpe2: 106.2360
[2025-10-18 14:14:00] [20251018131613] Epoch: 5, train loss1: 0.1686, train loss2: 0.4022, train loss3: 0.1798, train mpjpe1: 89.4661, train mpjpe2: 95.8977
[2025-10-18 14:14:00] [20251018131613] Epoch: 5,   val loss1: 0.1670,   val loss2: 0.3864,   val loss3: 0.1771,   val mpjpe1: 89.8334,   val mpjpe2: 96.9186
[2025-10-18 14:23:23] [20251018131613] Epoch: 6, train loss1: 0.1650, train loss2: 0.3908, train loss3: 0.1761, train mpjpe1: 87.7041, train mpjpe2: 94.1097
[2025-10-18 14:23:23] [20251018131613] Epoch: 6,   val loss1: 0.1665,   val loss2: 0.3765,   val loss3: 0.1777,   val mpjpe1: 91.0486,   val mpjpe2: 97.9829
[2025-10-18 14:32:58] [20251018131613] Epoch: 7, train loss1: 0.1613, train loss2: 0.3823, train loss3: 0.1730, train mpjpe1: 86.0989, train mpjpe2: 92.6181
[2025-10-18 14:32:58] [20251018131613] Epoch: 7,   val loss1: 0.1643,   val loss2: 0.3692,   val loss3: 0.1743,   val mpjpe1: 85.8257,   val mpjpe2: 93.2260
[2025-10-18 14:42:28] [20251018131613] Epoch: 8, train loss1: 0.1594, train loss2: 0.3759, train loss3: 0.1707, train mpjpe1: 85.1665, train mpjpe2: 91.7171
[2025-10-18 14:42:28] [20251018131613] Epoch: 8,   val loss1: 0.1594,   val loss2: 0.3682,   val loss3: 0.1702,   val mpjpe1: 87.8477,   val mpjpe2: 94.9966
[2025-10-18 14:51:59] [20251018131613] Epoch: 9, train loss1: 0.1545, train loss2: 0.3694, train loss3: 0.1658, train mpjpe1: 83.4360, train mpjpe2: 89.8432
[2025-10-18 14:51:59] [20251018131613] Epoch: 9,   val loss1: 0.1653,   val loss2: 0.3597,   val loss3: 0.1758,   val mpjpe1: 89.4315,   val mpjpe2: 96.1691
[2025-10-18 15:01:42] [20251018131613] Epoch: 10, train loss1: 0.1535, train loss2: 0.3668, train loss3: 0.1647, train mpjpe1: 82.6825, train mpjpe2: 89.1056
[2025-10-18 15:01:42] [20251018131613] Epoch: 10,   val loss1: 0.1538,   val loss2: 0.3592,   val loss3: 0.1642,   val mpjpe1: 83.7773,   val mpjpe2: 90.5557
[2025-10-18 15:11:09] [20251018131613] Epoch: 11, train loss1: 0.1510, train loss2: 0.3633, train loss3: 0.1622, train mpjpe1: 81.5015, train mpjpe2: 88.1835
[2025-10-18 15:11:09] [20251018131613] Epoch: 11,   val loss1: 0.1548,   val loss2: 0.3542,   val loss3: 0.1644,   val mpjpe1: 85.0506,   val mpjpe2: 91.4394
[2025-10-18 15:20:47] [20251018131613] Epoch: 12, train loss1: 0.1480, train loss2: 0.3603, train loss3: 0.1594, train mpjpe1: 80.5380, train mpjpe2: 87.0777
[2025-10-18 15:20:47] [20251018131613] Epoch: 12,   val loss1: 0.1509,   val loss2: 0.3578,   val loss3: 0.1615,   val mpjpe1: 82.9454,   val mpjpe2: 89.2421
[2025-10-18 15:30:19] [20251018131613] Epoch: 13, train loss1: 0.1466, train loss2: 0.3570, train loss3: 0.1580, train mpjpe1: 79.8630, train mpjpe2: 86.3883
[2025-10-18 15:30:19] [20251018131613] Epoch: 13,   val loss1: 0.1502,   val loss2: 0.3577,   val loss3: 0.1605,   val mpjpe1: 82.6381,   val mpjpe2: 89.5425
[2025-10-18 15:39:46] [20251018131613] Epoch: 14, train loss1: 0.1457, train loss2: 0.3551, train loss3: 0.1570, train mpjpe1: 79.3243, train mpjpe2: 85.8978
[2025-10-18 15:39:46] [20251018131613] Epoch: 14,   val loss1: 0.1483,   val loss2: 0.3484,   val loss3: 0.1582,   val mpjpe1: 83.5410,   val mpjpe2: 89.5850
[2025-10-18 15:49:20] [20251018131613] Epoch: 15, train loss1: 0.1427, train loss2: 0.3521, train loss3: 0.1539, train mpjpe1: 78.5293, train mpjpe2: 84.9925
[2025-10-18 15:49:20] [20251018131613] Epoch: 15,   val loss1: 0.1475,   val loss2: 0.3453,   val loss3: 0.1577,   val mpjpe1: 79.6850,   val mpjpe2: 86.6599
[2025-10-18 15:58:55] [20251018131613] Epoch: 16, train loss1: 0.1407, train loss2: 0.3487, train loss3: 0.1516, train mpjpe1: 77.3215, train mpjpe2: 83.9178
[2025-10-18 15:58:55] [20251018131613] Epoch: 16,   val loss1: 0.1476,   val loss2: 0.3453,   val loss3: 0.1581,   val mpjpe1: 83.8928,   val mpjpe2: 90.5638
[2025-10-18 16:08:16] [20251018131613] Epoch: 17, train loss1: 0.1397, train loss2: 0.3479, train loss3: 0.1508, train mpjpe1: 77.0975, train mpjpe2: 83.6077
[2025-10-18 16:08:16] [20251018131613] Epoch: 17,   val loss1: 0.1444,   val loss2: 0.3431,   val loss3: 0.1547,   val mpjpe1: 81.3334,   val mpjpe2: 88.6361
[2025-10-18 16:17:48] [20251018131613] Epoch: 18, train loss1: 0.1395, train loss2: 0.3457, train loss3: 0.1508, train mpjpe1: 76.4794, train mpjpe2: 83.2452
[2025-10-18 16:17:48] [20251018131613] Epoch: 18,   val loss1: 0.1438,   val loss2: 0.3478,   val loss3: 0.1546,   val mpjpe1: 79.8895,   val mpjpe2: 86.9868
[2025-10-18 16:27:19] [20251018131613] Epoch: 19, train loss1: 0.1366, train loss2: 0.3442, train loss3: 0.1477, train mpjpe1: 75.5278, train mpjpe2: 81.9138
[2025-10-18 16:27:19] [20251018131613] Epoch: 19,   val loss1: 0.1437,   val loss2: 0.3403,   val loss3: 0.1540,   val mpjpe1: 79.7324,   val mpjpe2: 86.5097
[2025-10-18 16:36:44] [20251018131613] Epoch: 20, train loss1: 0.1357, train loss2: 0.3422, train loss3: 0.1466, train mpjpe1: 74.9949, train mpjpe2: 81.5809
[2025-10-18 16:36:44] [20251018131613] Epoch: 20,   val loss1: 0.1434,   val loss2: 0.3451,   val loss3: 0.1541,   val mpjpe1: 80.5364,   val mpjpe2: 86.9187
[2025-10-18 16:45:38] [20251018131613] Epoch: 21, train loss1: 0.1345, train loss2: 0.3409, train loss3: 0.1454, train mpjpe1: 74.4074, train mpjpe2: 80.9356
[2025-10-18 16:45:38] [20251018131613] Epoch: 21,   val loss1: 0.1427,   val loss2: 0.3347,   val loss3: 0.1531,   val mpjpe1: 79.4549,   val mpjpe2: 85.6646
[2025-10-18 16:54:37] [20251018131613] Epoch: 22, train loss1: 0.1327, train loss2: 0.3388, train loss3: 0.1438, train mpjpe1: 73.7359, train mpjpe2: 80.3772
[2025-10-18 16:54:37] [20251018131613] Epoch: 22,   val loss1: 0.1408,   val loss2: 0.3398,   val loss3: 0.1511,   val mpjpe1: 78.5450,   val mpjpe2: 84.9298
[2025-10-18 17:03:36] [20251018131613] Epoch: 23, train loss1: 0.1307, train loss2: 0.3363, train loss3: 0.1413, train mpjpe1: 72.9869, train mpjpe2: 79.4003
[2025-10-18 17:03:36] [20251018131613] Epoch: 23,   val loss1: 0.1374,   val loss2: 0.3330,   val loss3: 0.1474,   val mpjpe1: 77.9505,   val mpjpe2: 84.8329
[2025-10-18 17:11:55] [20251018131613] Epoch: 24, train loss1: 0.1298, train loss2: 0.3345, train loss3: 0.1406, train mpjpe1: 72.5480, train mpjpe2: 78.9631
[2025-10-18 17:11:55] [20251018131613] Epoch: 24,   val loss1: 0.1369,   val loss2: 0.3315,   val loss3: 0.1477,   val mpjpe1: 78.4950,   val mpjpe2: 85.2241
[2025-10-18 17:20:03] [20251018131613] Epoch: 25, train loss1: 0.1279, train loss2: 0.3327, train loss3: 0.1381, train mpjpe1: 71.4631, train mpjpe2: 77.7147
[2025-10-18 17:20:03] [20251018131613] Epoch: 25,   val loss1: 0.1377,   val loss2: 0.3358,   val loss3: 0.1482,   val mpjpe1: 76.6670,   val mpjpe2: 82.8686
[2025-10-18 17:28:06] [20251018131613] Epoch: 26, train loss1: 0.1293, train loss2: 0.3337, train loss3: 0.1400, train mpjpe1: 71.9930, train mpjpe2: 78.3046
[2025-10-18 17:28:06] [20251018131613] Epoch: 26,   val loss1: 0.1394,   val loss2: 0.3380,   val loss3: 0.1505,   val mpjpe1: 77.2157,   val mpjpe2: 83.7866
[2025-10-18 17:35:56] [20251018131613] Epoch: 27, train loss1: 0.1256, train loss2: 0.3306, train loss3: 0.1359, train mpjpe1: 70.4440, train mpjpe2: 76.7318
[2025-10-18 17:35:56] [20251018131613] Epoch: 27,   val loss1: 0.1346,   val loss2: 0.3299,   val loss3: 0.1447,   val mpjpe1: 77.6393,   val mpjpe2: 83.7027
[2025-10-18 17:43:32] [20251018131613] Epoch: 28, train loss1: 0.1241, train loss2: 0.3286, train loss3: 0.1343, train mpjpe1: 69.9610, train mpjpe2: 76.0590
[2025-10-18 17:43:32] [20251018131613] Epoch: 28,   val loss1: 0.1360,   val loss2: 0.3353,   val loss3: 0.1466,   val mpjpe1: 76.4086,   val mpjpe2: 82.8949
[2025-10-18 17:50:49] [20251018131613] Epoch: 29, train loss1: 0.1237, train loss2: 0.3287, train loss3: 0.1342, train mpjpe1: 69.4559, train mpjpe2: 75.7019
[2025-10-18 17:50:49] [20251018131613] Epoch: 29,   val loss1: 0.1347,   val loss2: 0.3289,   val loss3: 0.1454,   val mpjpe1: 74.2562,   val mpjpe2: 80.1716
[2025-10-18 17:59:46] [20251018131613] Epoch: 30, train loss1: 0.1225, train loss2: 0.3271, train loss3: 0.1328, train mpjpe1: 68.9186, train mpjpe2: 75.1038
[2025-10-18 17:59:46] [20251018131613] Epoch: 30,   val loss1: 0.1334,   val loss2: 0.3284,   val loss3: 0.1441,   val mpjpe1: 76.1594,   val mpjpe2: 81.9805
[2025-10-18 18:08:37] [20251018131613] Epoch: 31, train loss1: 0.1215, train loss2: 0.3269, train loss3: 0.1318, train mpjpe1: 68.3924, train mpjpe2: 74.7566
[2025-10-18 18:08:37] [20251018131613] Epoch: 31,   val loss1: 0.1333,   val loss2: 0.3282,   val loss3: 0.1443,   val mpjpe1: 74.2797,   val mpjpe2: 80.4635
[2025-10-18 18:17:21] [20251018131613] Epoch: 32, train loss1: 0.1191, train loss2: 0.3242, train loss3: 0.1291, train mpjpe1: 67.5335, train mpjpe2: 73.5342
[2025-10-18 18:17:21] [20251018131613] Epoch: 32,   val loss1: 0.1316,   val loss2: 0.3274,   val loss3: 0.1414,   val mpjpe1: 75.0012,   val mpjpe2: 81.1789
[2025-10-18 18:25:48] [20251018131613] Epoch: 33, train loss1: 0.1188, train loss2: 0.3231, train loss3: 0.1290, train mpjpe1: 67.2125, train mpjpe2: 73.4057
[2025-10-18 18:25:48] [20251018131613] Epoch: 33,   val loss1: 0.1298,   val loss2: 0.3266,   val loss3: 0.1402,   val mpjpe1: 74.7937,   val mpjpe2: 80.5571
[2025-10-18 18:34:32] [20251018131613] Epoch: 34, train loss1: 0.1178, train loss2: 0.3220, train loss3: 0.1277, train mpjpe1: 66.6686, train mpjpe2: 72.6939
[2025-10-18 18:34:32] [20251018131613] Epoch: 34,   val loss1: 0.1284,   val loss2: 0.3263,   val loss3: 0.1380,   val mpjpe1: 73.9182,   val mpjpe2: 79.9164
[2025-10-18 18:43:20] [20251018131613] Epoch: 35, train loss1: 0.1169, train loss2: 0.3204, train loss3: 0.1269, train mpjpe1: 66.1777, train mpjpe2: 72.3408
[2025-10-18 18:43:20] [20251018131613] Epoch: 35,   val loss1: 0.1291,   val loss2: 0.3229,   val loss3: 0.1391,   val mpjpe1: 74.2762,   val mpjpe2: 80.1148
