[2025-10-18 13:17:27] 备注: 设备消融实验, exclude_device_idx = 1
[2025-10-18 13:17:27] exclude_device_idx=1, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:27:00] [20251018131727] Epoch: 0, train loss1: 0.2600, train loss2: 0.5872, train loss3: 0.2697, train mpjpe1: 122.8849, train mpjpe2: 130.6732
[2025-10-18 13:27:00] [20251018131727] Epoch: 0,   val loss1: 0.2238,   val loss2: 0.5045,   val loss3: 0.2342,   val mpjpe1: 114.6736,   val mpjpe2: 122.8090
[2025-10-18 13:36:12] [20251018131727] Epoch: 1, train loss1: 0.2057, train loss2: 0.4973, train loss3: 0.2148, train mpjpe1: 103.0343, train mpjpe2: 109.5099
[2025-10-18 13:36:12] [20251018131727] Epoch: 1,   val loss1: 0.2025,   val loss2: 0.4721,   val loss3: 0.2100,   val mpjpe1: 104.0374,   val mpjpe2: 108.8475
[2025-10-18 13:45:45] [20251018131727] Epoch: 2, train loss1: 0.1904, train loss2: 0.4651, train loss3: 0.2008, train mpjpe1: 98.1355, train mpjpe2: 104.4407
[2025-10-18 13:45:45] [20251018131727] Epoch: 2,   val loss1: 0.1806,   val loss2: 0.4416,   val loss3: 0.1926,   val mpjpe1: 96.8076,   val mpjpe2: 103.1215
[2025-10-18 13:55:03] [20251018131727] Epoch: 3, train loss1: 0.1802, train loss2: 0.4351, train loss3: 0.1911, train mpjpe1: 93.9419, train mpjpe2: 100.6600
[2025-10-18 13:55:03] [20251018131727] Epoch: 3,   val loss1: 0.1833,   val loss2: 0.4188,   val loss3: 0.1929,   val mpjpe1: 98.3160,   val mpjpe2: 103.6365
[2025-10-18 14:04:26] [20251018131727] Epoch: 4, train loss1: 0.1743, train loss2: 0.4103, train loss3: 0.1858, train mpjpe1: 91.8754, train mpjpe2: 98.3451
[2025-10-18 14:04:26] [20251018131727] Epoch: 4,   val loss1: 0.1756,   val loss2: 0.3960,   val loss3: 0.1849,   val mpjpe1: 94.8024,   val mpjpe2: 101.6042
[2025-10-18 14:13:51] [20251018131727] Epoch: 5, train loss1: 0.1693, train loss2: 0.3947, train loss3: 0.1811, train mpjpe1: 89.7808, train mpjpe2: 96.4482
[2025-10-18 14:13:51] [20251018131727] Epoch: 5,   val loss1: 0.1689,   val loss2: 0.3792,   val loss3: 0.1785,   val mpjpe1: 89.3345,   val mpjpe2: 96.6450
[2025-10-18 14:23:02] [20251018131727] Epoch: 6, train loss1: 0.1641, train loss2: 0.3854, train loss3: 0.1758, train mpjpe1: 87.6117, train mpjpe2: 94.3784
[2025-10-18 14:23:02] [20251018131727] Epoch: 6,   val loss1: 0.1635,   val loss2: 0.3706,   val loss3: 0.1729,   val mpjpe1: 88.9702,   val mpjpe2: 94.9935
[2025-10-18 14:32:25] [20251018131727] Epoch: 7, train loss1: 0.1607, train loss2: 0.3775, train loss3: 0.1723, train mpjpe1: 86.0119, train mpjpe2: 92.6848
[2025-10-18 14:32:25] [20251018131727] Epoch: 7,   val loss1: 0.1681,   val loss2: 0.3740,   val loss3: 0.1803,   val mpjpe1: 90.7291,   val mpjpe2: 98.1407
[2025-10-18 14:41:47] [20251018131727] Epoch: 8, train loss1: 0.1578, train loss2: 0.3727, train loss3: 0.1695, train mpjpe1: 84.6666, train mpjpe2: 91.3710
[2025-10-18 14:41:47] [20251018131727] Epoch: 8,   val loss1: 0.1581,   val loss2: 0.3634,   val loss3: 0.1691,   val mpjpe1: 84.9377,   val mpjpe2: 91.9472
[2025-10-18 14:51:15] [20251018131727] Epoch: 9, train loss1: 0.1542, train loss2: 0.3686, train loss3: 0.1658, train mpjpe1: 83.2542, train mpjpe2: 89.7874
[2025-10-18 14:51:15] [20251018131727] Epoch: 9,   val loss1: 0.1613,   val loss2: 0.3661,   val loss3: 0.1724,   val mpjpe1: 87.2590,   val mpjpe2: 95.2192
[2025-10-18 15:00:41] [20251018131727] Epoch: 10, train loss1: 0.1521, train loss2: 0.3637, train loss3: 0.1635, train mpjpe1: 82.3290, train mpjpe2: 88.8527
[2025-10-18 15:00:41] [20251018131727] Epoch: 10,   val loss1: 0.1522,   val loss2: 0.3559,   val loss3: 0.1618,   val mpjpe1: 82.6752,   val mpjpe2: 90.0618
[2025-10-18 15:10:08] [20251018131727] Epoch: 11, train loss1: 0.1495, train loss2: 0.3602, train loss3: 0.1609, train mpjpe1: 81.1483, train mpjpe2: 87.7101
[2025-10-18 15:10:08] [20251018131727] Epoch: 11,   val loss1: 0.1521,   val loss2: 0.3537,   val loss3: 0.1627,   val mpjpe1: 85.1889,   val mpjpe2: 91.3803
[2025-10-18 15:19:30] [20251018131727] Epoch: 12, train loss1: 0.1481, train loss2: 0.3575, train loss3: 0.1596, train mpjpe1: 80.7198, train mpjpe2: 87.2922
[2025-10-18 15:19:30] [20251018131727] Epoch: 12,   val loss1: 0.1538,   val loss2: 0.3616,   val loss3: 0.1660,   val mpjpe1: 84.6636,   val mpjpe2: 92.2838
[2025-10-18 15:29:04] [20251018131727] Epoch: 13, train loss1: 0.1474, train loss2: 0.3562, train loss3: 0.1589, train mpjpe1: 79.9358, train mpjpe2: 86.5204
[2025-10-18 15:29:04] [20251018131727] Epoch: 13,   val loss1: 0.1498,   val loss2: 0.3507,   val loss3: 0.1598,   val mpjpe1: 80.2726,   val mpjpe2: 87.2094
[2025-10-18 15:38:29] [20251018131727] Epoch: 14, train loss1: 0.1436, train loss2: 0.3523, train loss3: 0.1546, train mpjpe1: 78.9363, train mpjpe2: 85.3455
[2025-10-18 15:38:29] [20251018131727] Epoch: 14,   val loss1: 0.1485,   val loss2: 0.3506,   val loss3: 0.1585,   val mpjpe1: 81.8130,   val mpjpe2: 88.7903
[2025-10-18 15:47:37] [20251018131727] Epoch: 15, train loss1: 0.1426, train loss2: 0.3492, train loss3: 0.1537, train mpjpe1: 78.1033, train mpjpe2: 84.7220
[2025-10-18 15:47:37] [20251018131727] Epoch: 15,   val loss1: 0.1465,   val loss2: 0.3488,   val loss3: 0.1566,   val mpjpe1: 80.6203,   val mpjpe2: 87.2975
[2025-10-18 15:56:58] [20251018131727] Epoch: 16, train loss1: 0.1414, train loss2: 0.3486, train loss3: 0.1526, train mpjpe1: 77.6740, train mpjpe2: 84.1196
[2025-10-18 15:56:58] [20251018131727] Epoch: 16,   val loss1: 0.1461,   val loss2: 0.3443,   val loss3: 0.1568,   val mpjpe1: 79.7608,   val mpjpe2: 85.9936
[2025-10-18 16:06:18] [20251018131727] Epoch: 17, train loss1: 0.1394, train loss2: 0.3448, train loss3: 0.1505, train mpjpe1: 76.9306, train mpjpe2: 83.3743
[2025-10-18 16:06:18] [20251018131727] Epoch: 17,   val loss1: 0.1450,   val loss2: 0.3422,   val loss3: 0.1546,   val mpjpe1: 82.6688,   val mpjpe2: 88.6972
