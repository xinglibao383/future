[2025-10-18 13:17:27] 备注: 设备消融实验, exclude_device_idx = 1
[2025-10-18 13:17:27] exclude_device_idx=1, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 13:27:00] [20251018131727] Epoch: 0, train loss1: 0.2600, train loss2: 0.5872, train loss3: 0.2697, train mpjpe1: 122.8849, train mpjpe2: 130.6732
[2025-10-18 13:27:00] [20251018131727] Epoch: 0,   val loss1: 0.2238,   val loss2: 0.5045,   val loss3: 0.2342,   val mpjpe1: 114.6736,   val mpjpe2: 122.8090
[2025-10-18 13:36:12] [20251018131727] Epoch: 1, train loss1: 0.2057, train loss2: 0.4973, train loss3: 0.2148, train mpjpe1: 103.0343, train mpjpe2: 109.5099
[2025-10-18 13:36:12] [20251018131727] Epoch: 1,   val loss1: 0.2025,   val loss2: 0.4721,   val loss3: 0.2100,   val mpjpe1: 104.0374,   val mpjpe2: 108.8475
[2025-10-18 13:45:45] [20251018131727] Epoch: 2, train loss1: 0.1904, train loss2: 0.4651, train loss3: 0.2008, train mpjpe1: 98.1355, train mpjpe2: 104.4407
[2025-10-18 13:45:45] [20251018131727] Epoch: 2,   val loss1: 0.1806,   val loss2: 0.4416,   val loss3: 0.1926,   val mpjpe1: 96.8076,   val mpjpe2: 103.1215
[2025-10-18 13:55:03] [20251018131727] Epoch: 3, train loss1: 0.1802, train loss2: 0.4351, train loss3: 0.1911, train mpjpe1: 93.9419, train mpjpe2: 100.6600
[2025-10-18 13:55:03] [20251018131727] Epoch: 3,   val loss1: 0.1833,   val loss2: 0.4188,   val loss3: 0.1929,   val mpjpe1: 98.3160,   val mpjpe2: 103.6365
[2025-10-18 14:04:26] [20251018131727] Epoch: 4, train loss1: 0.1743, train loss2: 0.4103, train loss3: 0.1858, train mpjpe1: 91.8754, train mpjpe2: 98.3451
[2025-10-18 14:04:26] [20251018131727] Epoch: 4,   val loss1: 0.1756,   val loss2: 0.3960,   val loss3: 0.1849,   val mpjpe1: 94.8024,   val mpjpe2: 101.6042
[2025-10-18 14:13:51] [20251018131727] Epoch: 5, train loss1: 0.1693, train loss2: 0.3947, train loss3: 0.1811, train mpjpe1: 89.7808, train mpjpe2: 96.4482
[2025-10-18 14:13:51] [20251018131727] Epoch: 5,   val loss1: 0.1689,   val loss2: 0.3792,   val loss3: 0.1785,   val mpjpe1: 89.3345,   val mpjpe2: 96.6450
[2025-10-18 14:23:02] [20251018131727] Epoch: 6, train loss1: 0.1641, train loss2: 0.3854, train loss3: 0.1758, train mpjpe1: 87.6117, train mpjpe2: 94.3784
[2025-10-18 14:23:02] [20251018131727] Epoch: 6,   val loss1: 0.1635,   val loss2: 0.3706,   val loss3: 0.1729,   val mpjpe1: 88.9702,   val mpjpe2: 94.9935
[2025-10-18 14:32:25] [20251018131727] Epoch: 7, train loss1: 0.1607, train loss2: 0.3775, train loss3: 0.1723, train mpjpe1: 86.0119, train mpjpe2: 92.6848
[2025-10-18 14:32:25] [20251018131727] Epoch: 7,   val loss1: 0.1681,   val loss2: 0.3740,   val loss3: 0.1803,   val mpjpe1: 90.7291,   val mpjpe2: 98.1407
[2025-10-18 14:41:47] [20251018131727] Epoch: 8, train loss1: 0.1578, train loss2: 0.3727, train loss3: 0.1695, train mpjpe1: 84.6666, train mpjpe2: 91.3710
[2025-10-18 14:41:47] [20251018131727] Epoch: 8,   val loss1: 0.1581,   val loss2: 0.3634,   val loss3: 0.1691,   val mpjpe1: 84.9377,   val mpjpe2: 91.9472
[2025-10-18 14:51:15] [20251018131727] Epoch: 9, train loss1: 0.1542, train loss2: 0.3686, train loss3: 0.1658, train mpjpe1: 83.2542, train mpjpe2: 89.7874
[2025-10-18 14:51:15] [20251018131727] Epoch: 9,   val loss1: 0.1613,   val loss2: 0.3661,   val loss3: 0.1724,   val mpjpe1: 87.2590,   val mpjpe2: 95.2192
[2025-10-18 15:00:41] [20251018131727] Epoch: 10, train loss1: 0.1521, train loss2: 0.3637, train loss3: 0.1635, train mpjpe1: 82.3290, train mpjpe2: 88.8527
[2025-10-18 15:00:41] [20251018131727] Epoch: 10,   val loss1: 0.1522,   val loss2: 0.3559,   val loss3: 0.1618,   val mpjpe1: 82.6752,   val mpjpe2: 90.0618
[2025-10-18 15:10:08] [20251018131727] Epoch: 11, train loss1: 0.1495, train loss2: 0.3602, train loss3: 0.1609, train mpjpe1: 81.1483, train mpjpe2: 87.7101
[2025-10-18 15:10:08] [20251018131727] Epoch: 11,   val loss1: 0.1521,   val loss2: 0.3537,   val loss3: 0.1627,   val mpjpe1: 85.1889,   val mpjpe2: 91.3803
[2025-10-18 15:19:30] [20251018131727] Epoch: 12, train loss1: 0.1481, train loss2: 0.3575, train loss3: 0.1596, train mpjpe1: 80.7198, train mpjpe2: 87.2922
[2025-10-18 15:19:30] [20251018131727] Epoch: 12,   val loss1: 0.1538,   val loss2: 0.3616,   val loss3: 0.1660,   val mpjpe1: 84.6636,   val mpjpe2: 92.2838
[2025-10-18 15:29:04] [20251018131727] Epoch: 13, train loss1: 0.1474, train loss2: 0.3562, train loss3: 0.1589, train mpjpe1: 79.9358, train mpjpe2: 86.5204
[2025-10-18 15:29:04] [20251018131727] Epoch: 13,   val loss1: 0.1498,   val loss2: 0.3507,   val loss3: 0.1598,   val mpjpe1: 80.2726,   val mpjpe2: 87.2094
[2025-10-18 15:38:29] [20251018131727] Epoch: 14, train loss1: 0.1436, train loss2: 0.3523, train loss3: 0.1546, train mpjpe1: 78.9363, train mpjpe2: 85.3455
[2025-10-18 15:38:29] [20251018131727] Epoch: 14,   val loss1: 0.1485,   val loss2: 0.3506,   val loss3: 0.1585,   val mpjpe1: 81.8130,   val mpjpe2: 88.7903
[2025-10-18 15:47:37] [20251018131727] Epoch: 15, train loss1: 0.1426, train loss2: 0.3492, train loss3: 0.1537, train mpjpe1: 78.1033, train mpjpe2: 84.7220
[2025-10-18 15:47:37] [20251018131727] Epoch: 15,   val loss1: 0.1465,   val loss2: 0.3488,   val loss3: 0.1566,   val mpjpe1: 80.6203,   val mpjpe2: 87.2975
[2025-10-18 15:56:58] [20251018131727] Epoch: 16, train loss1: 0.1414, train loss2: 0.3486, train loss3: 0.1526, train mpjpe1: 77.6740, train mpjpe2: 84.1196
[2025-10-18 15:56:58] [20251018131727] Epoch: 16,   val loss1: 0.1461,   val loss2: 0.3443,   val loss3: 0.1568,   val mpjpe1: 79.7608,   val mpjpe2: 85.9936
[2025-10-18 16:06:18] [20251018131727] Epoch: 17, train loss1: 0.1394, train loss2: 0.3448, train loss3: 0.1505, train mpjpe1: 76.9306, train mpjpe2: 83.3743
[2025-10-18 16:06:18] [20251018131727] Epoch: 17,   val loss1: 0.1450,   val loss2: 0.3422,   val loss3: 0.1546,   val mpjpe1: 82.6688,   val mpjpe2: 88.6972
[2025-10-18 16:15:36] [20251018131727] Epoch: 18, train loss1: 0.1376, train loss2: 0.3436, train loss3: 0.1484, train mpjpe1: 75.8559, train mpjpe2: 82.2571
[2025-10-18 16:15:36] [20251018131727] Epoch: 18,   val loss1: 0.1445,   val loss2: 0.3427,   val loss3: 0.1550,   val mpjpe1: 79.3160,   val mpjpe2: 86.4089
[2025-10-18 16:24:59] [20251018131727] Epoch: 19, train loss1: 0.1364, train loss2: 0.3414, train loss3: 0.1469, train mpjpe1: 75.5180, train mpjpe2: 81.8435
[2025-10-18 16:24:59] [20251018131727] Epoch: 19,   val loss1: 0.1428,   val loss2: 0.3406,   val loss3: 0.1540,   val mpjpe1: 77.7282,   val mpjpe2: 84.4308
[2025-10-18 16:34:22] [20251018131727] Epoch: 20, train loss1: 0.1338, train loss2: 0.3387, train loss3: 0.1443, train mpjpe1: 74.6230, train mpjpe2: 80.9063
[2025-10-18 16:34:22] [20251018131727] Epoch: 20,   val loss1: 0.1408,   val loss2: 0.3365,   val loss3: 0.1497,   val mpjpe1: 75.8068,   val mpjpe2: 81.7654
[2025-10-18 16:43:17] [20251018131727] Epoch: 21, train loss1: 0.1327, train loss2: 0.3371, train loss3: 0.1434, train mpjpe1: 73.8587, train mpjpe2: 80.1205
[2025-10-18 16:43:17] [20251018131727] Epoch: 21,   val loss1: 0.1388,   val loss2: 0.3358,   val loss3: 0.1492,   val mpjpe1: 75.7347,   val mpjpe2: 82.6338
[2025-10-18 16:51:54] [20251018131727] Epoch: 22, train loss1: 0.1314, train loss2: 0.3360, train loss3: 0.1421, train mpjpe1: 73.2815, train mpjpe2: 79.5883
[2025-10-18 16:51:54] [20251018131727] Epoch: 22,   val loss1: 0.1379,   val loss2: 0.3390,   val loss3: 0.1482,   val mpjpe1: 74.9469,   val mpjpe2: 82.5960
[2025-10-18 17:00:42] [20251018131727] Epoch: 23, train loss1: 0.1301, train loss2: 0.3337, train loss3: 0.1407, train mpjpe1: 72.5850, train mpjpe2: 78.9917
[2025-10-18 17:00:42] [20251018131727] Epoch: 23,   val loss1: 0.1486,   val loss2: 0.3364,   val loss3: 0.1585,   val mpjpe1: 79.8283,   val mpjpe2: 86.5374
[2025-10-18 17:09:16] [20251018131727] Epoch: 24, train loss1: 0.1299, train loss2: 0.3354, train loss3: 0.1406, train mpjpe1: 72.4928, train mpjpe2: 78.8854
[2025-10-18 17:09:16] [20251018131727] Epoch: 24,   val loss1: 0.1369,   val loss2: 0.3338,   val loss3: 0.1471,   val mpjpe1: 76.1402,   val mpjpe2: 82.8574
[2025-10-18 17:17:17] [20251018131727] Epoch: 25, train loss1: 0.1273, train loss2: 0.3313, train loss3: 0.1376, train mpjpe1: 71.5368, train mpjpe2: 77.6966
[2025-10-18 17:17:17] [20251018131727] Epoch: 25,   val loss1: 0.1358,   val loss2: 0.3332,   val loss3: 0.1460,   val mpjpe1: 74.2061,   val mpjpe2: 81.2004
[2025-10-18 17:25:12] [20251018131727] Epoch: 26, train loss1: 0.1273, train loss2: 0.3310, train loss3: 0.1378, train mpjpe1: 71.1711, train mpjpe2: 77.5495
[2025-10-18 17:25:12] [20251018131727] Epoch: 26,   val loss1: 0.1360,   val loss2: 0.3297,   val loss3: 0.1454,   val mpjpe1: 74.9184,   val mpjpe2: 81.3960
[2025-10-18 17:33:04] [20251018131727] Epoch: 27, train loss1: 0.1258, train loss2: 0.3300, train loss3: 0.1362, train mpjpe1: 70.6789, train mpjpe2: 77.0087
[2025-10-18 17:33:04] [20251018131727] Epoch: 27,   val loss1: 0.1355,   val loss2: 0.3290,   val loss3: 0.1451,   val mpjpe1: 74.7553,   val mpjpe2: 81.7212
[2025-10-18 17:40:38] [20251018131727] Epoch: 28, train loss1: 0.1264, train loss2: 0.3294, train loss3: 0.1371, train mpjpe1: 70.5269, train mpjpe2: 76.9599
[2025-10-18 17:40:38] [20251018131727] Epoch: 28,   val loss1: 0.1337,   val loss2: 0.3318,   val loss3: 0.1440,   val mpjpe1: 73.3460,   val mpjpe2: 80.0651
[2025-10-18 17:47:53] [20251018131727] Epoch: 29, train loss1: 0.1229, train loss2: 0.3255, train loss3: 0.1333, train mpjpe1: 69.1892, train mpjpe2: 75.5033
[2025-10-18 17:47:53] [20251018131727] Epoch: 29,   val loss1: 0.1350,   val loss2: 0.3297,   val loss3: 0.1454,   val mpjpe1: 74.5403,   val mpjpe2: 81.5486
[2025-10-18 17:55:49] [20251018131727] Epoch: 30, train loss1: 0.1217, train loss2: 0.3252, train loss3: 0.1318, train mpjpe1: 68.6987, train mpjpe2: 74.8606
[2025-10-18 17:55:49] [20251018131727] Epoch: 30,   val loss1: 0.1335,   val loss2: 0.3284,   val loss3: 0.1442,   val mpjpe1: 75.5470,   val mpjpe2: 81.8765
[2025-10-18 18:04:46] [20251018131727] Epoch: 31, train loss1: 0.1211, train loss2: 0.3239, train loss3: 0.1311, train mpjpe1: 68.4109, train mpjpe2: 74.4996
[2025-10-18 18:04:46] [20251018131727] Epoch: 31,   val loss1: 0.1313,   val loss2: 0.3281,   val loss3: 0.1413,   val mpjpe1: 73.8634,   val mpjpe2: 80.5446
[2025-10-18 18:13:30] [20251018131727] Epoch: 32, train loss1: 0.1196, train loss2: 0.3223, train loss3: 0.1293, train mpjpe1: 67.8040, train mpjpe2: 73.8107
[2025-10-18 18:13:30] [20251018131727] Epoch: 32,   val loss1: 0.1299,   val loss2: 0.3273,   val loss3: 0.1400,   val mpjpe1: 72.7203,   val mpjpe2: 79.3439
[2025-10-18 18:22:21] [20251018131727] Epoch: 33, train loss1: 0.1181, train loss2: 0.3206, train loss3: 0.1282, train mpjpe1: 67.0037, train mpjpe2: 73.1217
[2025-10-18 18:22:21] [20251018131727] Epoch: 33,   val loss1: 0.1294,   val loss2: 0.3257,   val loss3: 0.1394,   val mpjpe1: 71.3158,   val mpjpe2: 78.0428
[2025-10-18 18:30:58] [20251018131727] Epoch: 34, train loss1: 0.1170, train loss2: 0.3184, train loss3: 0.1267, train mpjpe1: 66.2302, train mpjpe2: 72.3899
[2025-10-18 18:30:58] [20251018131727] Epoch: 34,   val loss1: 0.1312,   val loss2: 0.3257,   val loss3: 0.1418,   val mpjpe1: 71.1880,   val mpjpe2: 77.5660
[2025-10-18 18:39:40] [20251018131727] Epoch: 35, train loss1: 0.1167, train loss2: 0.3190, train loss3: 0.1272, train mpjpe1: 66.2470, train mpjpe2: 72.6625
[2025-10-18 18:39:40] [20251018131727] Epoch: 35,   val loss1: 0.1307,   val loss2: 0.3226,   val loss3: 0.1411,   val mpjpe1: 72.8888,   val mpjpe2: 79.4426
