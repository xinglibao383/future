[2025-10-18 17:49:04] 备注: 设备消融实验, exclude_device_idx = 2
[2025-10-18 17:49:04] exclude_device_idx=2, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 17:57:36] [20251018174904] Epoch: 0, train loss1: 0.2572, train loss2: 0.5874, train loss3: 0.2660, train mpjpe1: 119.0572, train mpjpe2: 125.9533
[2025-10-18 17:57:36] [20251018174904] Epoch: 0,   val loss1: 0.2131,   val loss2: 0.4997,   val loss3: 0.2205,   val mpjpe1: 106.2270,   val mpjpe2: 110.7332
[2025-10-18 18:06:24] [20251018174904] Epoch: 1, train loss1: 0.2070, train loss2: 0.4912, train loss3: 0.2158, train mpjpe1: 102.7715, train mpjpe2: 109.3460
[2025-10-18 18:06:24] [20251018174904] Epoch: 1,   val loss1: 0.1976,   val loss2: 0.4662,   val loss3: 0.2054,   val mpjpe1: 101.0920,   val mpjpe2: 104.9220
[2025-10-18 18:15:18] [20251018174904] Epoch: 2, train loss1: 0.1927, train loss2: 0.4623, train loss3: 0.2025, train mpjpe1: 99.1102, train mpjpe2: 105.5259
[2025-10-18 18:15:18] [20251018174904] Epoch: 2,   val loss1: 0.1854,   val loss2: 0.4403,   val loss3: 0.1986,   val mpjpe1: 100.3452,   val mpjpe2: 106.4669
[2025-10-18 18:24:13] [20251018174904] Epoch: 3, train loss1: 0.1841, train loss2: 0.4366, train loss3: 0.1948, train mpjpe1: 96.0350, train mpjpe2: 102.6672
[2025-10-18 18:24:13] [20251018174904] Epoch: 3,   val loss1: 0.1776,   val loss2: 0.4154,   val loss3: 0.1878,   val mpjpe1: 95.0802,   val mpjpe2: 100.6398
[2025-10-18 18:33:09] [20251018174904] Epoch: 4, train loss1: 0.1765, train loss2: 0.4139, train loss3: 0.1873, train mpjpe1: 92.9248, train mpjpe2: 99.8256
[2025-10-18 18:33:09] [20251018174904] Epoch: 4,   val loss1: 0.1752,   val loss2: 0.3910,   val loss3: 0.1862,   val mpjpe1: 90.4519,   val mpjpe2: 96.6323
[2025-10-18 18:42:08] [20251018174904] Epoch: 5, train loss1: 0.1723, train loss2: 0.3968, train loss3: 0.1835, train mpjpe1: 90.4130, train mpjpe2: 97.6249
[2025-10-18 18:42:08] [20251018174904] Epoch: 5,   val loss1: 0.1668,   val loss2: 0.3803,   val loss3: 0.1771,   val mpjpe1: 89.2224,   val mpjpe2: 95.2933
[2025-10-18 18:50:50] [20251018174904] Epoch: 6, train loss1: 0.1668, train loss2: 0.3835, train loss3: 0.1783, train mpjpe1: 88.4355, train mpjpe2: 95.3328
[2025-10-18 18:50:50] [20251018174904] Epoch: 6,   val loss1: 0.1668,   val loss2: 0.3709,   val loss3: 0.1780,   val mpjpe1: 86.2009,   val mpjpe2: 91.9402
[2025-10-18 18:59:23] [20251018174904] Epoch: 7, train loss1: 0.1623, train loss2: 0.3749, train loss3: 0.1734, train mpjpe1: 86.6685, train mpjpe2: 93.6894
[2025-10-18 18:59:23] [20251018174904] Epoch: 7,   val loss1: 0.1626,   val loss2: 0.3642,   val loss3: 0.1726,   val mpjpe1: 87.7488,   val mpjpe2: 91.8357
[2025-10-18 19:07:31] [20251018174904] Epoch: 8, train loss1: 0.1595, train loss2: 0.3676, train loss3: 0.1708, train mpjpe1: 85.3631, train mpjpe2: 92.1911
[2025-10-18 19:07:31] [20251018174904] Epoch: 8,   val loss1: 0.1610,   val loss2: 0.3533,   val loss3: 0.1710,   val mpjpe1: 86.2121,   val mpjpe2: 91.7118
[2025-10-18 19:15:32] [20251018174904] Epoch: 9, train loss1: 0.1585, train loss2: 0.3646, train loss3: 0.1700, train mpjpe1: 84.5625, train mpjpe2: 91.5857
[2025-10-18 19:15:32] [20251018174904] Epoch: 9,   val loss1: 0.1619,   val loss2: 0.3584,   val loss3: 0.1748,   val mpjpe1: 84.8337,   val mpjpe2: 91.8388
[2025-10-18 19:23:33] [20251018174904] Epoch: 10, train loss1: 0.1568, train loss2: 0.3600, train loss3: 0.1680, train mpjpe1: 83.9941, train mpjpe2: 90.9250
[2025-10-18 19:23:33] [20251018174904] Epoch: 10,   val loss1: 0.1529,   val loss2: 0.3439,   val loss3: 0.1637,   val mpjpe1: 82.8446,   val mpjpe2: 88.4595
[2025-10-18 19:31:42] [20251018174904] Epoch: 11, train loss1: 0.1519, train loss2: 0.3541, train loss3: 0.1634, train mpjpe1: 82.0733, train mpjpe2: 88.9789
[2025-10-18 19:31:42] [20251018174904] Epoch: 11,   val loss1: 0.1533,   val loss2: 0.3457,   val loss3: 0.1641,   val mpjpe1: 82.9691,   val mpjpe2: 88.3928
[2025-10-18 19:39:30] [20251018174904] Epoch: 12, train loss1: 0.1487, train loss2: 0.3513, train loss3: 0.1597, train mpjpe1: 81.0162, train mpjpe2: 87.9204
[2025-10-18 19:39:30] [20251018174904] Epoch: 12,   val loss1: 0.1525,   val loss2: 0.3438,   val loss3: 0.1628,   val mpjpe1: 82.9739,   val mpjpe2: 88.3389
[2025-10-18 19:47:16] [20251018174904] Epoch: 13, train loss1: 0.1474, train loss2: 0.3497, train loss3: 0.1588, train mpjpe1: 80.2274, train mpjpe2: 86.9574
[2025-10-18 19:47:16] [20251018174904] Epoch: 13,   val loss1: 0.1519,   val loss2: 0.3466,   val loss3: 0.1621,   val mpjpe1: 81.4528,   val mpjpe2: 87.8562
[2025-10-18 19:55:19] [20251018174904] Epoch: 14, train loss1: 0.1447, train loss2: 0.3472, train loss3: 0.1558, train mpjpe1: 79.3375, train mpjpe2: 85.9024
[2025-10-18 19:55:19] [20251018174904] Epoch: 14,   val loss1: 0.1480,   val loss2: 0.3400,   val loss3: 0.1580,   val mpjpe1: 81.1083,   val mpjpe2: 86.4842
[2025-10-18 20:03:24] [20251018174904] Epoch: 15, train loss1: 0.1451, train loss2: 0.3447, train loss3: 0.1561, train mpjpe1: 79.2380, train mpjpe2: 86.1560
[2025-10-18 20:03:24] [20251018174904] Epoch: 15,   val loss1: 0.1585,   val loss2: 0.3401,   val loss3: 0.1691,   val mpjpe1: 81.6997,   val mpjpe2: 87.4189
[2025-10-18 20:11:31] [20251018174904] Epoch: 16, train loss1: 0.1428, train loss2: 0.3420, train loss3: 0.1536, train mpjpe1: 78.2714, train mpjpe2: 84.9626
[2025-10-18 20:11:31] [20251018174904] Epoch: 16,   val loss1: 0.1462,   val loss2: 0.3365,   val loss3: 0.1566,   val mpjpe1: 80.5548,   val mpjpe2: 86.2238
[2025-10-18 20:19:29] [20251018174904] Epoch: 17, train loss1: 0.1406, train loss2: 0.3398, train loss3: 0.1517, train mpjpe1: 77.5130, train mpjpe2: 84.2576
[2025-10-18 20:19:29] [20251018174904] Epoch: 17,   val loss1: 0.1441,   val loss2: 0.3288,   val loss3: 0.1549,   val mpjpe1: 78.5503,   val mpjpe2: 83.7380
[2025-10-18 20:27:55] [20251018174904] Epoch: 18, train loss1: 0.1387, train loss2: 0.3373, train loss3: 0.1497, train mpjpe1: 76.7423, train mpjpe2: 83.3010
[2025-10-18 20:27:55] [20251018174904] Epoch: 18,   val loss1: 0.1462,   val loss2: 0.3307,   val loss3: 0.1565,   val mpjpe1: 81.6010,   val mpjpe2: 86.3212
[2025-10-18 20:37:12] [20251018174904] Epoch: 19, train loss1: 0.1380, train loss2: 0.3355, train loss3: 0.1489, train mpjpe1: 76.2626, train mpjpe2: 82.7647
[2025-10-18 20:37:12] [20251018174904] Epoch: 19,   val loss1: 0.1415,   val loss2: 0.3329,   val loss3: 0.1532,   val mpjpe1: 76.6052,   val mpjpe2: 82.5031
[2025-10-18 20:47:33] [20251018174904] Epoch: 20, train loss1: 0.1363, train loss2: 0.3329, train loss3: 0.1469, train mpjpe1: 75.6241, train mpjpe2: 82.1262
[2025-10-18 20:47:33] [20251018174904] Epoch: 20,   val loss1: 0.1476,   val loss2: 0.3294,   val loss3: 0.1595,   val mpjpe1: 79.2752,   val mpjpe2: 85.1096
[2025-10-18 20:58:37] [20251018174904] Epoch: 21, train loss1: 0.1359, train loss2: 0.3325, train loss3: 0.1467, train mpjpe1: 75.4076, train mpjpe2: 81.8669
[2025-10-18 20:58:37] [20251018174904] Epoch: 21,   val loss1: 0.1426,   val loss2: 0.3253,   val loss3: 0.1533,   val mpjpe1: 78.7301,   val mpjpe2: 83.6456
