[2025-10-18 17:51:29] 备注: 设备消融实验, exclude_device_idx = 3
[2025-10-18 17:51:29] exclude_device_idx=3, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 17:59:57] [20251018175129] Epoch: 0, train loss1: 0.2668, train loss2: 0.6094, train loss3: 0.2753, train mpjpe1: 121.9304, train mpjpe2: 128.7132
[2025-10-18 17:59:57] [20251018175129] Epoch: 0,   val loss1: 0.2190,   val loss2: 0.5311,   val loss3: 0.2281,   val mpjpe1: 111.5407,   val mpjpe2: 119.6967
[2025-10-18 18:08:52] [20251018175129] Epoch: 1, train loss1: 0.2091, train loss2: 0.5187, train loss3: 0.2192, train mpjpe1: 102.7660, train mpjpe2: 109.1818
[2025-10-18 18:08:52] [20251018175129] Epoch: 1,   val loss1: 0.1972,   val loss2: 0.4870,   val loss3: 0.2067,   val mpjpe1: 99.2598,   val mpjpe2: 104.5129
[2025-10-18 18:17:40] [20251018175129] Epoch: 2, train loss1: 0.1933, train loss2: 0.4834, train loss3: 0.2038, train mpjpe1: 98.3755, train mpjpe2: 104.4563
[2025-10-18 18:17:40] [20251018175129] Epoch: 2,   val loss1: 0.1867,   val loss2: 0.4625,   val loss3: 0.1950,   val mpjpe1: 98.3080,   val mpjpe2: 102.8082
[2025-10-18 18:26:36] [20251018175129] Epoch: 3, train loss1: 0.1841, train loss2: 0.4556, train loss3: 0.1950, train mpjpe1: 95.5662, train mpjpe2: 101.8255
[2025-10-18 18:26:36] [20251018175129] Epoch: 3,   val loss1: 0.1819,   val loss2: 0.4341,   val loss3: 0.1928,   val mpjpe1: 98.6868,   val mpjpe2: 104.8639
[2025-10-18 18:35:18] [20251018175129] Epoch: 4, train loss1: 0.1765, train loss2: 0.4337, train loss3: 0.1880, train mpjpe1: 92.5214, train mpjpe2: 99.3203
[2025-10-18 18:35:18] [20251018175129] Epoch: 4,   val loss1: 0.1812,   val loss2: 0.4249,   val loss3: 0.1892,   val mpjpe1: 93.8767,   val mpjpe2: 99.5894
[2025-10-18 18:44:05] [20251018175129] Epoch: 5, train loss1: 0.1701, train loss2: 0.4209, train loss3: 0.1814, train mpjpe1: 89.2687, train mpjpe2: 95.9745
[2025-10-18 18:44:05] [20251018175129] Epoch: 5,   val loss1: 0.1692,   val loss2: 0.4102,   val loss3: 0.1800,   val mpjpe1: 88.9209,   val mpjpe2: 94.6744
[2025-10-18 18:52:32] [20251018175129] Epoch: 6, train loss1: 0.1679, train loss2: 0.4127, train loss3: 0.1795, train mpjpe1: 88.2803, train mpjpe2: 94.8893
[2025-10-18 18:52:32] [20251018175129] Epoch: 6,   val loss1: 0.1664,   val loss2: 0.4018,   val loss3: 0.1776,   val mpjpe1: 90.2387,   val mpjpe2: 96.3851
[2025-10-18 19:00:57] [20251018175129] Epoch: 7, train loss1: 0.1634, train loss2: 0.4048, train loss3: 0.1750, train mpjpe1: 86.6133, train mpjpe2: 93.2793
[2025-10-18 19:00:57] [20251018175129] Epoch: 7,   val loss1: 0.1649,   val loss2: 0.3939,   val loss3: 0.1750,   val mpjpe1: 92.8816,   val mpjpe2: 98.9147
[2025-10-18 19:08:50] [20251018175129] Epoch: 8, train loss1: 0.1602, train loss2: 0.3994, train loss3: 0.1718, train mpjpe1: 85.2718, train mpjpe2: 92.1381
[2025-10-18 19:08:50] [20251018175129] Epoch: 8,   val loss1: 0.1642,   val loss2: 0.3956,   val loss3: 0.1735,   val mpjpe1: 91.1333,   val mpjpe2: 95.9950
[2025-10-18 19:16:40] [20251018175129] Epoch: 9, train loss1: 0.1575, train loss2: 0.3958, train loss3: 0.1695, train mpjpe1: 84.4575, train mpjpe2: 91.1670
[2025-10-18 19:16:40] [20251018175129] Epoch: 9,   val loss1: 0.1579,   val loss2: 0.3926,   val loss3: 0.1677,   val mpjpe1: 84.7316,   val mpjpe2: 90.4410
[2025-10-18 19:24:35] [20251018175129] Epoch: 10, train loss1: 0.1537, train loss2: 0.3914, train loss3: 0.1652, train mpjpe1: 82.7131, train mpjpe2: 89.3389
[2025-10-18 19:24:35] [20251018175129] Epoch: 10,   val loss1: 0.1557,   val loss2: 0.3871,   val loss3: 0.1652,   val mpjpe1: 82.5865,   val mpjpe2: 88.6978
[2025-10-18 19:32:18] [20251018175129] Epoch: 11, train loss1: 0.1537, train loss2: 0.3895, train loss3: 0.1654, train mpjpe1: 82.2568, train mpjpe2: 89.1323
[2025-10-18 19:32:18] [20251018175129] Epoch: 11,   val loss1: 0.1565,   val loss2: 0.3890,   val loss3: 0.1661,   val mpjpe1: 86.0504,   val mpjpe2: 91.2738
[2025-10-18 19:39:48] [20251018175129] Epoch: 12, train loss1: 0.1511, train loss2: 0.3876, train loss3: 0.1631, train mpjpe1: 81.0027, train mpjpe2: 88.0709
[2025-10-18 19:39:48] [20251018175129] Epoch: 12,   val loss1: 0.1543,   val loss2: 0.3877,   val loss3: 0.1653,   val mpjpe1: 84.0261,   val mpjpe2: 90.3478
[2025-10-18 19:47:17] [20251018175129] Epoch: 13, train loss1: 0.1491, train loss2: 0.3838, train loss3: 0.1607, train mpjpe1: 80.2393, train mpjpe2: 87.0027
[2025-10-18 19:47:17] [20251018175129] Epoch: 13,   val loss1: 0.1555,   val loss2: 0.3786,   val loss3: 0.1656,   val mpjpe1: 84.2744,   val mpjpe2: 90.3221
[2025-10-18 19:55:15] [20251018175129] Epoch: 14, train loss1: 0.1478, train loss2: 0.3810, train loss3: 0.1596, train mpjpe1: 79.6769, train mpjpe2: 86.4243
[2025-10-18 19:55:15] [20251018175129] Epoch: 14,   val loss1: 0.1527,   val loss2: 0.3830,   val loss3: 0.1624,   val mpjpe1: 82.3901,   val mpjpe2: 88.3828
[2025-10-18 20:03:01] [20251018175129] Epoch: 15, train loss1: 0.1432, train loss2: 0.3777, train loss3: 0.1545, train mpjpe1: 78.0197, train mpjpe2: 84.8901
[2025-10-18 20:03:01] [20251018175129] Epoch: 15,   val loss1: 0.1514,   val loss2: 0.3735,   val loss3: 0.1609,   val mpjpe1: 81.3632,   val mpjpe2: 87.1967
[2025-10-18 20:10:52] [20251018175129] Epoch: 16, train loss1: 0.1421, train loss2: 0.3753, train loss3: 0.1531, train mpjpe1: 77.6018, train mpjpe2: 84.4339
[2025-10-18 20:10:52] [20251018175129] Epoch: 16,   val loss1: 0.1479,   val loss2: 0.3753,   val loss3: 0.1583,   val mpjpe1: 82.6988,   val mpjpe2: 88.9054
[2025-10-18 20:18:39] [20251018175129] Epoch: 17, train loss1: 0.1406, train loss2: 0.3735, train loss3: 0.1517, train mpjpe1: 76.6537, train mpjpe2: 83.4108
[2025-10-18 20:18:39] [20251018175129] Epoch: 17,   val loss1: 0.1476,   val loss2: 0.3711,   val loss3: 0.1580,   val mpjpe1: 81.0711,   val mpjpe2: 86.5692
[2025-10-18 20:26:47] [20251018175129] Epoch: 18, train loss1: 0.1404, train loss2: 0.3728, train loss3: 0.1521, train mpjpe1: 76.6391, train mpjpe2: 83.8130
[2025-10-18 20:26:47] [20251018175129] Epoch: 18,   val loss1: 0.1485,   val loss2: 0.3725,   val loss3: 0.1591,   val mpjpe1: 80.3998,   val mpjpe2: 86.9322
[2025-10-18 20:35:52] [20251018175129] Epoch: 19, train loss1: 0.1377, train loss2: 0.3699, train loss3: 0.1489, train mpjpe1: 75.7898, train mpjpe2: 82.4925
[2025-10-18 20:35:52] [20251018175129] Epoch: 19,   val loss1: 0.1492,   val loss2: 0.3723,   val loss3: 0.1596,   val mpjpe1: 82.9506,   val mpjpe2: 88.0652
[2025-10-18 20:45:48] [20251018175129] Epoch: 20, train loss1: 0.1347, train loss2: 0.3675, train loss3: 0.1457, train mpjpe1: 74.6215, train mpjpe2: 81.2980
[2025-10-18 20:45:48] [20251018175129] Epoch: 20,   val loss1: 0.1450,   val loss2: 0.3694,   val loss3: 0.1542,   val mpjpe1: 78.9341,   val mpjpe2: 85.5044
[2025-10-18 20:56:31] [20251018175129] Epoch: 21, train loss1: 0.1340, train loss2: 0.3658, train loss3: 0.1449, train mpjpe1: 74.0530, train mpjpe2: 80.6239
[2025-10-18 20:56:31] [20251018175129] Epoch: 21,   val loss1: 0.1458,   val loss2: 0.3710,   val loss3: 0.1553,   val mpjpe1: 84.3718,   val mpjpe2: 88.4965
