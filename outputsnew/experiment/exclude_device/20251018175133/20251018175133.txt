[2025-10-18 17:51:33] 备注: 设备消融实验, exclude_device_idx = 3
[2025-10-18 17:51:33] exclude_device_idx=3, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 18:00:20] [20251018175133] Epoch: 0, train loss1: 0.2624, train loss2: 0.6060, train loss3: 0.2727, train mpjpe1: 119.6050, train mpjpe2: 126.7545
[2025-10-18 18:00:20] [20251018175133] Epoch: 0,   val loss1: 0.2212,   val loss2: 0.5392,   val loss3: 0.2343,   val mpjpe1: 112.6317,   val mpjpe2: 118.7391
[2025-10-18 18:08:54] [20251018175133] Epoch: 1, train loss1: 0.2090, train loss2: 0.5107, train loss3: 0.2186, train mpjpe1: 104.1064, train mpjpe2: 110.1969
[2025-10-18 18:08:54] [20251018175133] Epoch: 1,   val loss1: 0.2075,   val loss2: 0.4823,   val loss3: 0.2200,   val mpjpe1: 106.4654,   val mpjpe2: 111.2539
[2025-10-18 18:17:24] [20251018175133] Epoch: 2, train loss1: 0.1925, train loss2: 0.4826, train loss3: 0.2032, train mpjpe1: 99.3533, train mpjpe2: 105.3484
[2025-10-18 18:17:24] [20251018175133] Epoch: 2,   val loss1: 0.1902,   val loss2: 0.4659,   val loss3: 0.2031,   val mpjpe1: 98.4974,   val mpjpe2: 105.2809
[2025-10-18 18:26:11] [20251018175133] Epoch: 3, train loss1: 0.1828, train loss2: 0.4588, train loss3: 0.1942, train mpjpe1: 95.4703, train mpjpe2: 101.7011
[2025-10-18 18:26:11] [20251018175133] Epoch: 3,   val loss1: 0.1830,   val loss2: 0.4395,   val loss3: 0.1928,   val mpjpe1: 97.6867,   val mpjpe2: 103.6664
[2025-10-18 18:34:38] [20251018175133] Epoch: 4, train loss1: 0.1773, train loss2: 0.4379, train loss3: 0.1888, train mpjpe1: 92.8442, train mpjpe2: 99.3284
[2025-10-18 18:34:38] [20251018175133] Epoch: 4,   val loss1: 0.1770,   val loss2: 0.4265,   val loss3: 0.1892,   val mpjpe1: 90.0971,   val mpjpe2: 96.5964
[2025-10-18 18:43:14] [20251018175133] Epoch: 5, train loss1: 0.1713, train loss2: 0.4249, train loss3: 0.1830, train mpjpe1: 90.4077, train mpjpe2: 96.8357
[2025-10-18 18:43:14] [20251018175133] Epoch: 5,   val loss1: 0.1680,   val loss2: 0.4136,   val loss3: 0.1798,   val mpjpe1: 87.7472,   val mpjpe2: 94.2407
[2025-10-18 18:51:30] [20251018175133] Epoch: 6, train loss1: 0.1673, train loss2: 0.4168, train loss3: 0.1789, train mpjpe1: 88.5984, train mpjpe2: 95.0829
[2025-10-18 18:51:30] [20251018175133] Epoch: 6,   val loss1: 0.1668,   val loss2: 0.4044,   val loss3: 0.1787,   val mpjpe1: 89.4239,   val mpjpe2: 94.9627
[2025-10-18 18:59:45] [20251018175133] Epoch: 7, train loss1: 0.1633, train loss2: 0.4102, train loss3: 0.1747, train mpjpe1: 86.8197, train mpjpe2: 93.2190
[2025-10-18 18:59:45] [20251018175133] Epoch: 7,   val loss1: 0.1669,   val loss2: 0.4025,   val loss3: 0.1781,   val mpjpe1: 91.3642,   val mpjpe2: 97.3161
[2025-10-18 19:07:36] [20251018175133] Epoch: 8, train loss1: 0.1607, train loss2: 0.4049, train loss3: 0.1725, train mpjpe1: 85.5716, train mpjpe2: 92.2139
[2025-10-18 19:07:36] [20251018175133] Epoch: 8,   val loss1: 0.1612,   val loss2: 0.3948,   val loss3: 0.1722,   val mpjpe1: 87.6300,   val mpjpe2: 93.7901
[2025-10-18 19:15:26] [20251018175133] Epoch: 9, train loss1: 0.1579, train loss2: 0.4001, train loss3: 0.1698, train mpjpe1: 84.5105, train mpjpe2: 91.5206
[2025-10-18 19:15:26] [20251018175133] Epoch: 9,   val loss1: 0.1620,   val loss2: 0.3994,   val loss3: 0.1751,   val mpjpe1: 86.1749,   val mpjpe2: 93.2524
[2025-10-18 19:23:08] [20251018175133] Epoch: 10, train loss1: 0.1548, train loss2: 0.3951, train loss3: 0.1665, train mpjpe1: 83.1131, train mpjpe2: 89.9080
[2025-10-18 19:23:08] [20251018175133] Epoch: 10,   val loss1: 0.1601,   val loss2: 0.3853,   val loss3: 0.1708,   val mpjpe1: 86.5389,   val mpjpe2: 92.2274
[2025-10-18 19:30:56] [20251018175133] Epoch: 11, train loss1: 0.1526, train loss2: 0.3927, train loss3: 0.1643, train mpjpe1: 82.1852, train mpjpe2: 88.9801
[2025-10-18 19:30:56] [20251018175133] Epoch: 11,   val loss1: 0.1603,   val loss2: 0.3954,   val loss3: 0.1715,   val mpjpe1: 85.2911,   val mpjpe2: 91.8150
[2025-10-18 19:38:42] [20251018175133] Epoch: 12, train loss1: 0.1518, train loss2: 0.3898, train loss3: 0.1633, train mpjpe1: 81.6389, train mpjpe2: 88.6683
[2025-10-18 19:38:42] [20251018175133] Epoch: 12,   val loss1: 0.1528,   val loss2: 0.3799,   val loss3: 0.1641,   val mpjpe1: 82.6041,   val mpjpe2: 88.4270
[2025-10-18 19:46:25] [20251018175133] Epoch: 13, train loss1: 0.1504, train loss2: 0.3865, train loss3: 0.1623, train mpjpe1: 80.7428, train mpjpe2: 87.6220
[2025-10-18 19:46:25] [20251018175133] Epoch: 13,   val loss1: 0.1571,   val loss2: 0.3825,   val loss3: 0.1687,   val mpjpe1: 82.0307,   val mpjpe2: 88.8031
[2025-10-18 19:54:11] [20251018175133] Epoch: 14, train loss1: 0.1470, train loss2: 0.3819, train loss3: 0.1583, train mpjpe1: 79.8861, train mpjpe2: 86.7200
[2025-10-18 19:54:11] [20251018175133] Epoch: 14,   val loss1: 0.1520,   val loss2: 0.3802,   val loss3: 0.1645,   val mpjpe1: 80.6110,   val mpjpe2: 87.6111
[2025-10-18 20:01:50] [20251018175133] Epoch: 15, train loss1: 0.1444, train loss2: 0.3795, train loss3: 0.1556, train mpjpe1: 78.7037, train mpjpe2: 85.5257
[2025-10-18 20:01:50] [20251018175133] Epoch: 15,   val loss1: 0.1490,   val loss2: 0.3739,   val loss3: 0.1605,   val mpjpe1: 82.1938,   val mpjpe2: 88.6217
[2025-10-18 20:09:38] [20251018175133] Epoch: 16, train loss1: 0.1424, train loss2: 0.3763, train loss3: 0.1534, train mpjpe1: 77.8394, train mpjpe2: 84.5843
[2025-10-18 20:09:38] [20251018175133] Epoch: 16,   val loss1: 0.1472,   val loss2: 0.3700,   val loss3: 0.1589,   val mpjpe1: 80.6039,   val mpjpe2: 87.2608
[2025-10-18 20:17:11] [20251018175133] Epoch: 17, train loss1: 0.1406, train loss2: 0.3746, train loss3: 0.1519, train mpjpe1: 77.1073, train mpjpe2: 84.0403
[2025-10-18 20:17:11] [20251018175133] Epoch: 17,   val loss1: 0.1497,   val loss2: 0.3733,   val loss3: 0.1603,   val mpjpe1: 79.9322,   val mpjpe2: 86.8787
[2025-10-18 20:24:44] [20251018175133] Epoch: 18, train loss1: 0.1397, train loss2: 0.3731, train loss3: 0.1510, train mpjpe1: 76.6036, train mpjpe2: 83.5792
[2025-10-18 20:24:44] [20251018175133] Epoch: 18,   val loss1: 0.1522,   val loss2: 0.3727,   val loss3: 0.1642,   val mpjpe1: 81.5529,   val mpjpe2: 87.5812
[2025-10-18 20:33:52] [20251018175133] Epoch: 19, train loss1: 0.1386, train loss2: 0.3710, train loss3: 0.1497, train mpjpe1: 76.0707, train mpjpe2: 82.7945
[2025-10-18 20:33:52] [20251018175133] Epoch: 19,   val loss1: 0.1486,   val loss2: 0.3673,   val loss3: 0.1600,   val mpjpe1: 77.3776,   val mpjpe2: 84.2727
[2025-10-18 20:43:12] [20251018175133] Epoch: 20, train loss1: 0.1355, train loss2: 0.3683, train loss3: 0.1463, train mpjpe1: 74.8501, train mpjpe2: 81.6280
[2025-10-18 20:43:12] [20251018175133] Epoch: 20,   val loss1: 0.1429,   val loss2: 0.3658,   val loss3: 0.1543,   val mpjpe1: 77.0962,   val mpjpe2: 83.5119
[2025-10-18 20:54:18] [20251018175133] Epoch: 21, train loss1: 0.1341, train loss2: 0.3666, train loss3: 0.1450, train mpjpe1: 74.2939, train mpjpe2: 81.1267
[2025-10-18 20:54:18] [20251018175133] Epoch: 21,   val loss1: 0.1430,   val loss2: 0.3663,   val loss3: 0.1554,   val mpjpe1: 77.9577,   val mpjpe2: 84.3045
