[2025-10-18 17:52:45] 备注: 设备消融实验, exclude_device_idx = 4
[2025-10-18 17:52:45] exclude_device_idx=4, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 18:01:38] [20251018175245] Epoch: 0, train loss1: 0.2548, train loss2: 0.6095, train loss3: 0.2653, train mpjpe1: 118.8700, train mpjpe2: 126.2245
[2025-10-18 18:01:38] [20251018175245] Epoch: 0,   val loss1: 0.2103,   val loss2: 0.5257,   val loss3: 0.2184,   val mpjpe1: 107.5231,   val mpjpe2: 112.0990
[2025-10-18 18:10:00] [20251018175245] Epoch: 1, train loss1: 0.2034, train loss2: 0.5165, train loss3: 0.2131, train mpjpe1: 101.6722, train mpjpe2: 107.9267
[2025-10-18 18:10:00] [20251018175245] Epoch: 1,   val loss1: 0.1964,   val loss2: 0.4929,   val loss3: 0.2035,   val mpjpe1: 104.3436,   val mpjpe2: 109.8563
[2025-10-18 18:18:30] [20251018175245] Epoch: 2, train loss1: 0.1878, train loss2: 0.4837, train loss3: 0.1980, train mpjpe1: 96.5951, train mpjpe2: 102.7068
[2025-10-18 18:18:30] [20251018175245] Epoch: 2,   val loss1: 0.1802,   val loss2: 0.4713,   val loss3: 0.1914,   val mpjpe1: 92.6640,   val mpjpe2: 98.3054
[2025-10-18 18:26:45] [20251018175245] Epoch: 3, train loss1: 0.1792, train loss2: 0.4607, train loss3: 0.1902, train mpjpe1: 93.5710, train mpjpe2: 99.8806
[2025-10-18 18:26:45] [20251018175245] Epoch: 3,   val loss1: 0.1785,   val loss2: 0.4453,   val loss3: 0.1884,   val mpjpe1: 94.3789,   val mpjpe2: 100.5300
[2025-10-18 18:35:25] [20251018175245] Epoch: 4, train loss1: 0.1733, train loss2: 0.4357, train loss3: 0.1847, train mpjpe1: 90.6289, train mpjpe2: 97.2211
[2025-10-18 18:35:25] [20251018175245] Epoch: 4,   val loss1: 0.1691,   val loss2: 0.4331,   val loss3: 0.1783,   val mpjpe1: 92.8375,   val mpjpe2: 96.5956
[2025-10-18 18:44:04] [20251018175245] Epoch: 5, train loss1: 0.1664, train loss2: 0.4205, train loss3: 0.1780, train mpjpe1: 88.0264, train mpjpe2: 94.6850
[2025-10-18 18:44:04] [20251018175245] Epoch: 5,   val loss1: 0.1681,   val loss2: 0.4084,   val loss3: 0.1789,   val mpjpe1: 92.3527,   val mpjpe2: 98.2002
[2025-10-18 18:52:27] [20251018175245] Epoch: 6, train loss1: 0.1628, train loss2: 0.4110, train loss3: 0.1748, train mpjpe1: 86.5401, train mpjpe2: 93.1605
[2025-10-18 18:52:27] [20251018175245] Epoch: 6,   val loss1: 0.1642,   val loss2: 0.4050,   val loss3: 0.1740,   val mpjpe1: 89.9488,   val mpjpe2: 94.3105
[2025-10-18 19:00:25] [20251018175245] Epoch: 7, train loss1: 0.1602, train loss2: 0.4035, train loss3: 0.1720, train mpjpe1: 85.6930, train mpjpe2: 92.1799
[2025-10-18 19:00:25] [20251018175245] Epoch: 7,   val loss1: 0.1688,   val loss2: 0.3941,   val loss3: 0.1780,   val mpjpe1: 89.1071,   val mpjpe2: 93.3693
[2025-10-18 19:08:19] [20251018175245] Epoch: 8, train loss1: 0.1567, train loss2: 0.3966, train loss3: 0.1682, train mpjpe1: 84.1483, train mpjpe2: 90.4913
[2025-10-18 19:08:19] [20251018175245] Epoch: 8,   val loss1: 0.1593,   val loss2: 0.3951,   val loss3: 0.1686,   val mpjpe1: 86.3758,   val mpjpe2: 91.0556
[2025-10-18 19:16:18] [20251018175245] Epoch: 9, train loss1: 0.1534, train loss2: 0.3914, train loss3: 0.1649, train mpjpe1: 82.9217, train mpjpe2: 89.2895
[2025-10-18 19:16:18] [20251018175245] Epoch: 9,   val loss1: 0.1577,   val loss2: 0.3898,   val loss3: 0.1677,   val mpjpe1: 85.5924,   val mpjpe2: 90.3766
[2025-10-18 19:24:17] [20251018175245] Epoch: 10, train loss1: 0.1527, train loss2: 0.3884, train loss3: 0.1642, train mpjpe1: 82.3410, train mpjpe2: 88.7321
[2025-10-18 19:24:17] [20251018175245] Epoch: 10,   val loss1: 0.1564,   val loss2: 0.3840,   val loss3: 0.1668,   val mpjpe1: 86.4317,   val mpjpe2: 91.7854
[2025-10-18 19:32:18] [20251018175245] Epoch: 11, train loss1: 0.1516, train loss2: 0.3862, train loss3: 0.1633, train mpjpe1: 81.5662, train mpjpe2: 88.0623
[2025-10-18 19:32:18] [20251018175245] Epoch: 11,   val loss1: 0.1549,   val loss2: 0.3860,   val loss3: 0.1661,   val mpjpe1: 86.2707,   val mpjpe2: 91.8022
[2025-10-18 19:40:20] [20251018175245] Epoch: 12, train loss1: 0.1488, train loss2: 0.3816, train loss3: 0.1602, train mpjpe1: 80.8435, train mpjpe2: 87.3586
[2025-10-18 19:40:20] [20251018175245] Epoch: 12,   val loss1: 0.1516,   val loss2: 0.3794,   val loss3: 0.1621,   val mpjpe1: 81.9000,   val mpjpe2: 87.7437
[2025-10-18 19:48:16] [20251018175245] Epoch: 13, train loss1: 0.1444, train loss2: 0.3780, train loss3: 0.1555, train mpjpe1: 79.0411, train mpjpe2: 85.5437
[2025-10-18 19:48:16] [20251018175245] Epoch: 13,   val loss1: 0.1483,   val loss2: 0.3763,   val loss3: 0.1582,   val mpjpe1: 80.2933,   val mpjpe2: 85.9094
[2025-10-18 19:55:58] [20251018175245] Epoch: 14, train loss1: 0.1433, train loss2: 0.3755, train loss3: 0.1544, train mpjpe1: 78.4258, train mpjpe2: 84.9242
[2025-10-18 19:55:58] [20251018175245] Epoch: 14,   val loss1: 0.1473,   val loss2: 0.3814,   val loss3: 0.1584,   val mpjpe1: 79.5652,   val mpjpe2: 85.5297
[2025-10-18 20:04:05] [20251018175245] Epoch: 15, train loss1: 0.1413, train loss2: 0.3739, train loss3: 0.1526, train mpjpe1: 77.7265, train mpjpe2: 84.3287
[2025-10-18 20:04:05] [20251018175245] Epoch: 15,   val loss1: 0.1457,   val loss2: 0.3763,   val loss3: 0.1563,   val mpjpe1: 81.6395,   val mpjpe2: 86.5831
[2025-10-18 20:11:55] [20251018175245] Epoch: 16, train loss1: 0.1396, train loss2: 0.3715, train loss3: 0.1506, train mpjpe1: 76.8890, train mpjpe2: 83.3813
[2025-10-18 20:11:55] [20251018175245] Epoch: 16,   val loss1: 0.1488,   val loss2: 0.3745,   val loss3: 0.1589,   val mpjpe1: 82.5970,   val mpjpe2: 87.4342
[2025-10-18 20:19:58] [20251018175245] Epoch: 17, train loss1: 0.1383, train loss2: 0.3695, train loss3: 0.1492, train mpjpe1: 76.1728, train mpjpe2: 82.8272
[2025-10-18 20:19:58] [20251018175245] Epoch: 17,   val loss1: 0.1434,   val loss2: 0.3703,   val loss3: 0.1530,   val mpjpe1: 80.2618,   val mpjpe2: 85.9800
[2025-10-18 20:27:48] [20251018175245] Epoch: 18, train loss1: 0.1374, train loss2: 0.3683, train loss3: 0.1485, train mpjpe1: 75.5434, train mpjpe2: 82.1371
[2025-10-18 20:27:48] [20251018175245] Epoch: 18,   val loss1: 0.1480,   val loss2: 0.3778,   val loss3: 0.1586,   val mpjpe1: 81.9889,   val mpjpe2: 87.1242
[2025-10-18 20:37:10] [20251018175245] Epoch: 19, train loss1: 0.1357, train loss2: 0.3661, train loss3: 0.1467, train mpjpe1: 75.3118, train mpjpe2: 81.8666
[2025-10-18 20:37:10] [20251018175245] Epoch: 19,   val loss1: 0.1388,   val loss2: 0.3660,   val loss3: 0.1485,   val mpjpe1: 76.8157,   val mpjpe2: 82.6634
[2025-10-18 20:46:56] [20251018175245] Epoch: 20, train loss1: 0.1350, train loss2: 0.3663, train loss3: 0.1461, train mpjpe1: 74.2939, train mpjpe2: 81.1604
[2025-10-18 20:46:56] [20251018175245] Epoch: 20,   val loss1: 0.1407,   val loss2: 0.3659,   val loss3: 0.1505,   val mpjpe1: 79.1593,   val mpjpe2: 84.3526
[2025-10-18 20:58:06] [20251018175245] Epoch: 21, train loss1: 0.1329, train loss2: 0.3632, train loss3: 0.1436, train mpjpe1: 73.5508, train mpjpe2: 80.0457
[2025-10-18 20:58:06] [20251018175245] Epoch: 21,   val loss1: 0.1389,   val loss2: 0.3677,   val loss3: 0.1492,   val mpjpe1: 75.7288,   val mpjpe2: 81.2757
