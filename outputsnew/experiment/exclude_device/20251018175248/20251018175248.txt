[2025-10-18 17:52:48] 备注: 设备消融实验, exclude_device_idx = 4
[2025-10-18 17:52:48] exclude_device_idx=4, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 18:01:41] [20251018175248] Epoch: 0, train loss1: 0.2547, train loss2: 0.6068, train loss3: 0.2633, train mpjpe1: 118.4679, train mpjpe2: 125.4661
[2025-10-18 18:01:41] [20251018175248] Epoch: 0,   val loss1: 0.2154,   val loss2: 0.5246,   val loss3: 0.2221,   val mpjpe1: 106.9201,   val mpjpe2: 112.0657
[2025-10-18 18:10:04] [20251018175248] Epoch: 1, train loss1: 0.2039, train loss2: 0.5180, train loss3: 0.2131, train mpjpe1: 102.1204, train mpjpe2: 107.8713
[2025-10-18 18:10:04] [20251018175248] Epoch: 1,   val loss1: 0.1907,   val loss2: 0.4871,   val loss3: 0.2006,   val mpjpe1: 97.8138,   val mpjpe2: 103.5400
[2025-10-18 18:18:36] [20251018175248] Epoch: 2, train loss1: 0.1883, train loss2: 0.4802, train loss3: 0.1983, train mpjpe1: 96.7369, train mpjpe2: 102.7404
[2025-10-18 18:18:36] [20251018175248] Epoch: 2,   val loss1: 0.1837,   val loss2: 0.4547,   val loss3: 0.1955,   val mpjpe1: 95.9920,   val mpjpe2: 101.9385
[2025-10-18 18:26:57] [20251018175248] Epoch: 3, train loss1: 0.1804, train loss2: 0.4513, train loss3: 0.1911, train mpjpe1: 93.7144, train mpjpe2: 99.8217
[2025-10-18 18:26:57] [20251018175248] Epoch: 3,   val loss1: 0.1714,   val loss2: 0.4337,   val loss3: 0.1821,   val mpjpe1: 90.7599,   val mpjpe2: 95.9083
[2025-10-18 18:35:32] [20251018175248] Epoch: 4, train loss1: 0.1739, train loss2: 0.4315, train loss3: 0.1848, train mpjpe1: 90.9960, train mpjpe2: 97.2161
[2025-10-18 18:35:32] [20251018175248] Epoch: 4,   val loss1: 0.1686,   val loss2: 0.4187,   val loss3: 0.1788,   val mpjpe1: 89.2300,   val mpjpe2: 93.8509
[2025-10-18 18:44:14] [20251018175248] Epoch: 5, train loss1: 0.1679, train loss2: 0.4177, train loss3: 0.1788, train mpjpe1: 89.0956, train mpjpe2: 95.3095
[2025-10-18 18:44:14] [20251018175248] Epoch: 5,   val loss1: 0.1633,   val loss2: 0.4136,   val loss3: 0.1747,   val mpjpe1: 87.8442,   val mpjpe2: 93.5372
[2025-10-18 18:52:41] [20251018175248] Epoch: 6, train loss1: 0.1648, train loss2: 0.4082, train loss3: 0.1760, train mpjpe1: 87.6426, train mpjpe2: 94.0679
[2025-10-18 18:52:41] [20251018175248] Epoch: 6,   val loss1: 0.1641,   val loss2: 0.4017,   val loss3: 0.1752,   val mpjpe1: 88.3799,   val mpjpe2: 94.4166
[2025-10-18 19:00:45] [20251018175248] Epoch: 7, train loss1: 0.1610, train loss2: 0.4013, train loss3: 0.1724, train mpjpe1: 85.8082, train mpjpe2: 92.2444
[2025-10-18 19:00:45] [20251018175248] Epoch: 7,   val loss1: 0.1586,   val loss2: 0.3996,   val loss3: 0.1701,   val mpjpe1: 88.0628,   val mpjpe2: 93.2799
[2025-10-18 19:08:45] [20251018175248] Epoch: 8, train loss1: 0.1581, train loss2: 0.3954, train loss3: 0.1694, train mpjpe1: 84.9303, train mpjpe2: 91.0445
[2025-10-18 19:08:45] [20251018175248] Epoch: 8,   val loss1: 0.1568,   val loss2: 0.3883,   val loss3: 0.1681,   val mpjpe1: 86.8206,   val mpjpe2: 91.8350
[2025-10-18 19:16:46] [20251018175248] Epoch: 9, train loss1: 0.1559, train loss2: 0.3912, train loss3: 0.1672, train mpjpe1: 83.7441, train mpjpe2: 90.1163
[2025-10-18 19:16:46] [20251018175248] Epoch: 9,   val loss1: 0.1566,   val loss2: 0.3920,   val loss3: 0.1697,   val mpjpe1: 85.3048,   val mpjpe2: 91.3408
[2025-10-18 19:24:46] [20251018175248] Epoch: 10, train loss1: 0.1543, train loss2: 0.3882, train loss3: 0.1655, train mpjpe1: 83.2615, train mpjpe2: 89.3909
[2025-10-18 19:24:46] [20251018175248] Epoch: 10,   val loss1: 0.1535,   val loss2: 0.3849,   val loss3: 0.1652,   val mpjpe1: 81.6241,   val mpjpe2: 87.3100
[2025-10-18 19:32:55] [20251018175248] Epoch: 11, train loss1: 0.1508, train loss2: 0.3849, train loss3: 0.1621, train mpjpe1: 81.8510, train mpjpe2: 88.1662
[2025-10-18 19:32:55] [20251018175248] Epoch: 11,   val loss1: 0.1503,   val loss2: 0.3853,   val loss3: 0.1624,   val mpjpe1: 84.1069,   val mpjpe2: 89.3210
[2025-10-18 19:40:51] [20251018175248] Epoch: 12, train loss1: 0.1488, train loss2: 0.3813, train loss3: 0.1599, train mpjpe1: 81.1466, train mpjpe2: 87.5541
[2025-10-18 19:40:51] [20251018175248] Epoch: 12,   val loss1: 0.1493,   val loss2: 0.3766,   val loss3: 0.1605,   val mpjpe1: 82.9508,   val mpjpe2: 88.2228
[2025-10-18 19:48:57] [20251018175248] Epoch: 13, train loss1: 0.1461, train loss2: 0.3786, train loss3: 0.1571, train mpjpe1: 79.7555, train mpjpe2: 86.0357
[2025-10-18 19:48:57] [20251018175248] Epoch: 13,   val loss1: 0.1476,   val loss2: 0.3801,   val loss3: 0.1589,   val mpjpe1: 80.3144,   val mpjpe2: 85.9125
[2025-10-18 19:56:59] [20251018175248] Epoch: 14, train loss1: 0.1447, train loss2: 0.3764, train loss3: 0.1557, train mpjpe1: 79.3170, train mpjpe2: 85.7828
[2025-10-18 19:56:59] [20251018175248] Epoch: 14,   val loss1: 0.1482,   val loss2: 0.3730,   val loss3: 0.1603,   val mpjpe1: 81.5109,   val mpjpe2: 87.1668
[2025-10-18 20:04:58] [20251018175248] Epoch: 15, train loss1: 0.1435, train loss2: 0.3750, train loss3: 0.1547, train mpjpe1: 78.6765, train mpjpe2: 84.9725
[2025-10-18 20:04:58] [20251018175248] Epoch: 15,   val loss1: 0.1474,   val loss2: 0.3739,   val loss3: 0.1586,   val mpjpe1: 78.2846,   val mpjpe2: 83.8566
[2025-10-18 20:12:53] [20251018175248] Epoch: 16, train loss1: 0.1424, train loss2: 0.3725, train loss3: 0.1532, train mpjpe1: 78.2826, train mpjpe2: 84.6053
[2025-10-18 20:12:53] [20251018175248] Epoch: 16,   val loss1: 0.1438,   val loss2: 0.3762,   val loss3: 0.1548,   val mpjpe1: 80.5660,   val mpjpe2: 86.4230
[2025-10-18 20:20:46] [20251018175248] Epoch: 17, train loss1: 0.1397, train loss2: 0.3698, train loss3: 0.1502, train mpjpe1: 77.1040, train mpjpe2: 83.3966
[2025-10-18 20:20:46] [20251018175248] Epoch: 17,   val loss1: 0.1427,   val loss2: 0.3743,   val loss3: 0.1538,   val mpjpe1: 77.1993,   val mpjpe2: 83.4339
[2025-10-18 20:29:25] [20251018175248] Epoch: 18, train loss1: 0.1377, train loss2: 0.3681, train loss3: 0.1482, train mpjpe1: 76.4189, train mpjpe2: 82.8875
[2025-10-18 20:29:25] [20251018175248] Epoch: 18,   val loss1: 0.1404,   val loss2: 0.3656,   val loss3: 0.1518,   val mpjpe1: 77.3672,   val mpjpe2: 83.5724
[2025-10-18 20:38:48] [20251018175248] Epoch: 19, train loss1: 0.1346, train loss2: 0.3645, train loss3: 0.1448, train mpjpe1: 75.0695, train mpjpe2: 81.2388
[2025-10-18 20:38:48] [20251018175248] Epoch: 19,   val loss1: 0.1362,   val loss2: 0.3646,   val loss3: 0.1470,   val mpjpe1: 74.7284,   val mpjpe2: 80.5698
[2025-10-18 20:49:34] [20251018175248] Epoch: 20, train loss1: 0.1339, train loss2: 0.3634, train loss3: 0.1442, train mpjpe1: 74.5689, train mpjpe2: 80.7725
[2025-10-18 20:49:34] [20251018175248] Epoch: 20,   val loss1: 0.1406,   val loss2: 0.3655,   val loss3: 0.1517,   val mpjpe1: 76.3520,   val mpjpe2: 82.8073
[2025-10-18 21:00:24] [20251018175248] Epoch: 21, train loss1: 0.1342, train loss2: 0.3627, train loss3: 0.1449, train mpjpe1: 74.6403, train mpjpe2: 80.8305
[2025-10-18 21:00:24] [20251018175248] Epoch: 21,   val loss1: 0.1387,   val loss2: 0.3669,   val loss3: 0.1502,   val mpjpe1: 76.5397,   val mpjpe2: 82.0312
