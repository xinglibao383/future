[2025-10-18 17:54:53] 备注: 设备消融实验, exclude_device_idx = 2
[2025-10-18 17:54:53] exclude_device_idx=2, mask_ratio=0.25, batch_size=256, lr=0.001, epochs=300, loss_func=l1, resnet_verson=resnet18, imu_generator=transformer, transformer_hidden=128, transformer_layers=2, transformer_nhead=4, transformer_dropout=0.1, use_len=60, compute_len=15, predict_len=15, stride_len=15, need_normalize=True, alpha=1, beta=1, gamma=1
[2025-10-18 18:03:40] [20251018175453] Epoch: 0, train loss1: 0.2600, train loss2: 0.5797, train loss3: 0.2697, train mpjpe1: 121.5442, train mpjpe2: 128.4074
[2025-10-18 18:03:40] [20251018175453] Epoch: 0,   val loss1: 0.2115,   val loss2: 0.5103,   val loss3: 0.2210,   val mpjpe1: 107.4078,   val mpjpe2: 112.8697
[2025-10-18 18:12:29] [20251018175453] Epoch: 1, train loss1: 0.2106, train loss2: 0.4917, train loss3: 0.2194, train mpjpe1: 104.2382, train mpjpe2: 110.1827
[2025-10-18 18:12:29] [20251018175453] Epoch: 1,   val loss1: 0.2149,   val loss2: 0.4637,   val loss3: 0.2252,   val mpjpe1: 104.1637,   val mpjpe2: 109.7847
[2025-10-18 18:21:07] [20251018175453] Epoch: 2, train loss1: 0.1960, train loss2: 0.4580, train loss3: 0.2060, train mpjpe1: 99.6933, train mpjpe2: 105.7956
[2025-10-18 18:21:07] [20251018175453] Epoch: 2,   val loss1: 0.1879,   val loss2: 0.4373,   val loss3: 0.1969,   val mpjpe1: 97.5824,   val mpjpe2: 102.8619
[2025-10-18 18:29:44] [20251018175453] Epoch: 3, train loss1: 0.1848, train loss2: 0.4342, train loss3: 0.1951, train mpjpe1: 96.0898, train mpjpe2: 102.0324
[2025-10-18 18:29:44] [20251018175453] Epoch: 3,   val loss1: 0.1929,   val loss2: 0.4206,   val loss3: 0.2082,   val mpjpe1: 97.8211,   val mpjpe2: 104.6448
[2025-10-18 18:38:24] [20251018175453] Epoch: 4, train loss1: 0.1793, train loss2: 0.4088, train loss3: 0.1903, train mpjpe1: 93.5943, train mpjpe2: 99.6403
[2025-10-18 18:38:24] [20251018175453] Epoch: 4,   val loss1: 0.1780,   val loss2: 0.3879,   val loss3: 0.1890,   val mpjpe1: 93.1006,   val mpjpe2: 99.5150
[2025-10-18 18:47:01] [20251018175453] Epoch: 5, train loss1: 0.1729, train loss2: 0.3897, train loss3: 0.1844, train mpjpe1: 91.0641, train mpjpe2: 97.6860
[2025-10-18 18:47:01] [20251018175453] Epoch: 5,   val loss1: 0.1736,   val loss2: 0.3800,   val loss3: 0.1832,   val mpjpe1: 91.3443,   val mpjpe2: 97.7937
[2025-10-18 18:55:23] [20251018175453] Epoch: 6, train loss1: 0.1679, train loss2: 0.3787, train loss3: 0.1791, train mpjpe1: 88.7548, train mpjpe2: 95.1502
[2025-10-18 18:55:23] [20251018175453] Epoch: 6,   val loss1: 0.1729,   val loss2: 0.3713,   val loss3: 0.1838,   val mpjpe1: 92.0438,   val mpjpe2: 98.2584
[2025-10-18 19:03:39] [20251018175453] Epoch: 7, train loss1: 0.1657, train loss2: 0.3710, train loss3: 0.1769, train mpjpe1: 88.1479, train mpjpe2: 94.5358
[2025-10-18 19:03:39] [20251018175453] Epoch: 7,   val loss1: 0.1629,   val loss2: 0.3577,   val loss3: 0.1735,   val mpjpe1: 89.0125,   val mpjpe2: 95.1585
[2025-10-18 19:11:33] [20251018175453] Epoch: 8, train loss1: 0.1599, train loss2: 0.3633, train loss3: 0.1712, train mpjpe1: 85.9862, train mpjpe2: 92.3889
[2025-10-18 19:11:33] [20251018175453] Epoch: 8,   val loss1: 0.1596,   val loss2: 0.3534,   val loss3: 0.1696,   val mpjpe1: 86.4387,   val mpjpe2: 92.5431
[2025-10-18 19:19:23] [20251018175453] Epoch: 9, train loss1: 0.1575, train loss2: 0.3591, train loss3: 0.1688, train mpjpe1: 84.4916, train mpjpe2: 91.1955
[2025-10-18 19:19:23] [20251018175453] Epoch: 9,   val loss1: 0.1584,   val loss2: 0.3566,   val loss3: 0.1693,   val mpjpe1: 86.3219,   val mpjpe2: 92.1723
[2025-10-18 19:27:18] [20251018175453] Epoch: 10, train loss1: 0.1558, train loss2: 0.3565, train loss3: 0.1674, train mpjpe1: 83.8500, train mpjpe2: 90.5357
[2025-10-18 19:27:18] [20251018175453] Epoch: 10,   val loss1: 0.1682,   val loss2: 0.3539,   val loss3: 0.1770,   val mpjpe1: 87.7313,   val mpjpe2: 93.0261
[2025-10-18 19:35:19] [20251018175453] Epoch: 11, train loss1: 0.1537, train loss2: 0.3537, train loss3: 0.1651, train mpjpe1: 82.7816, train mpjpe2: 89.4515
[2025-10-18 19:35:19] [20251018175453] Epoch: 11,   val loss1: 0.1515,   val loss2: 0.3480,   val loss3: 0.1621,   val mpjpe1: 85.1242,   val mpjpe2: 91.2215
[2025-10-18 19:43:19] [20251018175453] Epoch: 12, train loss1: 0.1488, train loss2: 0.3488, train loss3: 0.1600, train mpjpe1: 81.0843, train mpjpe2: 87.6184
[2025-10-18 19:43:19] [20251018175453] Epoch: 12,   val loss1: 0.1515,   val loss2: 0.3452,   val loss3: 0.1620,   val mpjpe1: 81.1040,   val mpjpe2: 87.6009
[2025-10-18 19:51:16] [20251018175453] Epoch: 13, train loss1: 0.1480, train loss2: 0.3457, train loss3: 0.1596, train mpjpe1: 80.3728, train mpjpe2: 86.9493
[2025-10-18 19:51:16] [20251018175453] Epoch: 13,   val loss1: 0.1521,   val loss2: 0.3435,   val loss3: 0.1622,   val mpjpe1: 83.4812,   val mpjpe2: 88.7393
[2025-10-18 19:59:02] [20251018175453] Epoch: 14, train loss1: 0.1465, train loss2: 0.3444, train loss3: 0.1577, train mpjpe1: 79.7348, train mpjpe2: 86.1682
[2025-10-18 19:59:02] [20251018175453] Epoch: 14,   val loss1: 0.1484,   val loss2: 0.3435,   val loss3: 0.1591,   val mpjpe1: 79.8169,   val mpjpe2: 86.0406
[2025-10-18 20:06:59] [20251018175453] Epoch: 15, train loss1: 0.1471, train loss2: 0.3437, train loss3: 0.1582, train mpjpe1: 79.9485, train mpjpe2: 86.3697
[2025-10-18 20:06:59] [20251018175453] Epoch: 15,   val loss1: 0.1477,   val loss2: 0.3384,   val loss3: 0.1577,   val mpjpe1: 80.9864,   val mpjpe2: 87.0868
[2025-10-18 20:14:49] [20251018175453] Epoch: 16, train loss1: 0.1426, train loss2: 0.3392, train loss3: 0.1537, train mpjpe1: 78.3469, train mpjpe2: 84.6882
[2025-10-18 20:14:49] [20251018175453] Epoch: 16,   val loss1: 0.1453,   val loss2: 0.3369,   val loss3: 0.1551,   val mpjpe1: 80.9771,   val mpjpe2: 86.5638
[2025-10-18 20:22:53] [20251018175453] Epoch: 17, train loss1: 0.1404, train loss2: 0.3366, train loss3: 0.1514, train mpjpe1: 77.4225, train mpjpe2: 83.8041
[2025-10-18 20:22:53] [20251018175453] Epoch: 17,   val loss1: 0.1439,   val loss2: 0.3323,   val loss3: 0.1542,   val mpjpe1: 82.4275,   val mpjpe2: 88.1992
[2025-10-18 20:31:56] [20251018175453] Epoch: 18, train loss1: 0.1398, train loss2: 0.3353, train loss3: 0.1509, train mpjpe1: 77.1613, train mpjpe2: 83.5082
[2025-10-18 20:31:56] [20251018175453] Epoch: 18,   val loss1: 0.1431,   val loss2: 0.3326,   val loss3: 0.1528,   val mpjpe1: 79.6814,   val mpjpe2: 85.9640
[2025-10-18 20:41:24] [20251018175453] Epoch: 19, train loss1: 0.1383, train loss2: 0.3324, train loss3: 0.1492, train mpjpe1: 76.4028, train mpjpe2: 82.7728
[2025-10-18 20:41:24] [20251018175453] Epoch: 19,   val loss1: 0.1417,   val loss2: 0.3325,   val loss3: 0.1536,   val mpjpe1: 77.2496,   val mpjpe2: 83.8581
[2025-10-18 20:52:04] [20251018175453] Epoch: 20, train loss1: 0.1372, train loss2: 0.3324, train loss3: 0.1481, train mpjpe1: 75.9245, train mpjpe2: 82.3369
[2025-10-18 20:52:04] [20251018175453] Epoch: 20,   val loss1: 0.1419,   val loss2: 0.3322,   val loss3: 0.1528,   val mpjpe1: 77.8552,   val mpjpe2: 84.8184
[2025-10-18 21:02:55] [20251018175453] Epoch: 21, train loss1: 0.1362, train loss2: 0.3295, train loss3: 0.1471, train mpjpe1: 75.2248, train mpjpe2: 81.7181
[2025-10-18 21:02:55] [20251018175453] Epoch: 21,   val loss1: 0.1454,   val loss2: 0.3317,   val loss3: 0.1550,   val mpjpe1: 81.1814,   val mpjpe2: 87.3486
