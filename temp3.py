import torchvision
torchvision.disable_beta_transforms_warning()

import warnings
warnings.filterwarnings("ignore")

from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection
from sentence_transformers import SentenceTransformer
import torch

# ========== å‚æ•°é…ç½® ==========
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"
COLLECTION_NAME = "doc_demo"
EMBEDDING_DIM = 1024  # bge-large-zh ç»´åº¦

# ========== åˆå§‹åŒ–å‘é‡æ¨¡å‹ ==========
device = "cuda" if torch.cuda.is_available() else "cpu"
model = SentenceTransformer("/home/xinglibao/workspace/future/embedding/bge-large-zh-v1.5")

def embed_text(text):
    text = "ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢: " + text
    embedding = model.encode(text, normalize_embeddings=True)
    return embedding

# ========== è¿æ¥ Milvus ==========
connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)

# ========== åˆ›å»º Collection ==========
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIM),
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=1000)
]
schema = CollectionSchema(fields, description="Demo collection")
collection = Collection(name=COLLECTION_NAME, schema=schema)
collection.create_index(field_name="embedding", index_params={"index_type": "IVF_FLAT", "metric_type": "L2", "params": {"nlist": 128}})
collection.load()

# ========== åŠ è½½æ–‡æ¡£å¹¶æ’å…¥ ==========
docs = [
    "æ³¨å†Œä¼šè®¡å¸ˆè€ƒè¯•åŒ…æ‹¬ã€Šä¼šè®¡ã€‹ã€Šå®¡è®¡ã€‹ã€Šç¨æ³•ã€‹ã€Šè´¢åŠ¡æˆæœ¬ç®¡ç†ã€‹ã€Šç»æµæ³•ã€‹ã€Šå…¬å¸æˆ˜ç•¥ä¸é£é™©ç®¡ç†ã€‹å…­é—¨ç§‘ç›®ã€‚",
    "è€ƒè¯•æ—¶é—´ä¸€èˆ¬å®‰æ’åœ¨æ¯å¹´çš„åæœˆã€‚",
    "è€ƒç”Ÿéœ€è¦é€šè¿‡æ‰€æœ‰ç§‘ç›®æ‰èƒ½è·å¾—å…¨ç§‘åˆæ ¼è¯ä¹¦ã€‚",
    "ä¸€èˆ¬ç¨‹åºå‘˜å–œæ¬¢åƒç«é”…",
]

embeddings = [embed_text(d) for d in docs]
insert_data = [embeddings, docs]
collection.insert(insert_data)
collection.flush()

print("âœ… å‘é‡å·²å†™å…¥ Milvusï¼")

# ========== å‘é‡æŸ¥è¯¢ ==========
query_text = "æ³¨å†Œä¼šè®¡å¸ˆè€ƒä»€ä¹ˆå†…å®¹ï¼Ÿ"
query_vector = embed_text(query_text)

results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param={"metric_type": "L2", "params": {"nprobe": 10}},
    limit=3,
    output_fields=["text"]
)

print("\nğŸ” æŸ¥è¯¢ç»“æœï¼š")
for hit in results[0]:
    print(f"- ç›¸ä¼¼å†…å®¹: {hit.entity.get('text')}ï¼ˆè·ç¦»: {hit.distance:.4f}ï¼‰")